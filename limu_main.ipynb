{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'general': {'test_mode': 'One_out', 'window_size': 150, 'overlap': 0.8, 'pretrain_model': None, 'batch_size': 128, 'freeze': False}, 'kdd_pretrain': {'epoch': 3200, 'lr': 0.0001, 'optimizer': 'RAdam', 'weight_decay': None, 'harden': False}, 'limu_pretrain': {'epoch': 3200, 'lr': 0.0001, 'optimizer': 'Adam', 'weight_decay': None, 'harden': False}, 'limu_mask': {'mask_ratio': 0.15, 'mask_alpha': 6, 'max_gram': 10, 'mask_prob': 0.8, 'replace_prob': 0.0}, 'kdd_model': {'d_hidden': 128, 'd_ff': 256, 'n_heads': 16, 'n_layers': 3, 'dropout': 0.1, 'pos_encoding': 'learnable', 'activation': 'gelu', 'norm': 'BatchNorm', 'projection': 'linear'}, 'limu_model': {'d_hidden': 72, 'd_ff': 144, 'n_heads': 4, 'n_layers': 4, 'emb_norm': False}}\n",
      "Class: BROWSE -> Encoded Value: 0\n",
      "Class: PLAY -> Encoded Value: 1\n",
      "Class: READ -> Encoded Value: 2\n",
      "Class: SEARCH -> Encoded Value: 3\n",
      "Class: WATCH -> Encoded Value: 4\n",
      "Class: WRITE -> Encoded Value: 5\n",
      "The number of classes is 6, the feat_dim is 2\n",
      "Model:\n",
      "LIMUBertModel4Pretrain(\n",
      "  (transformer): Transformer_Original(\n",
      "    (embed): Embeddings(\n",
      "      (lin): Linear(in_features=2, out_features=72, bias=True)\n",
      "      (pos_embed): Embedding(150, 72)\n",
      "      (norm): LayerNorm()\n",
      "    )\n",
      "    (attn): MultiHeadedSelfAttention(\n",
      "      (proj_q): Linear(in_features=72, out_features=72, bias=True)\n",
      "      (proj_k): Linear(in_features=72, out_features=72, bias=True)\n",
      "      (proj_v): Linear(in_features=72, out_features=72, bias=True)\n",
      "    )\n",
      "    (proj): Linear(in_features=72, out_features=72, bias=True)\n",
      "    (norm1): LayerNorm()\n",
      "    (pwff): PositionWiseFeedForward(\n",
      "      (fc1): Linear(in_features=72, out_features=144, bias=True)\n",
      "      (fc2): Linear(in_features=144, out_features=72, bias=True)\n",
      "    )\n",
      "    (norm2): LayerNorm()\n",
      "  )\n",
      "  (fc): Linear(in_features=72, out_features=72, bias=True)\n",
      "  (linear): Linear(in_features=72, out_features=72, bias=True)\n",
      "  (norm): LayerNorm()\n",
      "  (decoder): Linear(in_features=72, out_features=2, bias=True)\n",
      ")\n",
      "Total number of parameters: 64226\n",
      "Trainable parameters: 64226\n",
      "=============================================================\n",
      "=====================Training via cuda===================\n",
      "=============================================================\n",
      "Epoch 1/3200, Train Loss: 0.0379, Time: 7.5370564460754395\n",
      "Epoch 2/3200, Train Loss: 0.0076, Time: 4.934761047363281\n",
      "Epoch 3/3200, Train Loss: 0.0067, Time: 4.941553831100464\n",
      "Epoch 4/3200, Train Loss: 0.0065, Time: 4.941404819488525\n",
      "Epoch 5/3200, Train Loss: 0.0065, Time: 4.950546026229858\n",
      "Epoch 6/3200, Train Loss: 0.0064, Time: 4.955054998397827\n",
      "Epoch 7/3200, Train Loss: 0.0065, Time: 4.956564903259277\n",
      "Epoch 8/3200, Train Loss: 0.0065, Time: 4.939322471618652\n",
      "Epoch 9/3200, Train Loss: 0.0063, Time: 4.961278915405273\n",
      "Epoch 10/3200, Train Loss: 0.0063, Time: 4.971026420593262\n",
      "Epoch 11/3200, Train Loss: 0.0064, Time: 4.971052646636963\n",
      "Epoch 12/3200, Train Loss: 0.0063, Time: 4.951112985610962\n",
      "Epoch 13/3200, Train Loss: 0.0063, Time: 4.959626913070679\n",
      "Epoch 14/3200, Train Loss: 0.0063, Time: 4.972498178482056\n",
      "Epoch 15/3200, Train Loss: 0.0062, Time: 4.960954904556274\n",
      "Epoch 16/3200, Train Loss: 0.0063, Time: 4.95203423500061\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import sys\n",
    "\n",
    "from modules.limu_model import limu_model4pretrain\n",
    "from modules.pretrain_hyperparameters import LIMU_Pretrain_Hyperparameters\n",
    "from utils.load_data_from_file import load_mixed_data, prepare_mixed_data_loader, load_one_out_data, \\\n",
    "    prepare_one_out_data_loader, limu_prepare_mixed_data_loader, limu_prepare_one_out_data_loader\n",
    "from utils.pretrain import pretrain_limu_model\n",
    "\n",
    "\n",
    "def main():\n",
    "    # Load the config from JSON file first\n",
    "    with open(\"utils/config.json\", \"r\") as file:\n",
    "        config = json.load(file)\n",
    "    print(config)\n",
    "\n",
    "    if config[\"general\"][\"test_mode\"] == \"Mixed\":\n",
    "        data, labels, encoder = load_mixed_data(window_size=config[\"general\"][\"window_size\"],\n",
    "                                                overlap=config[\"general\"][\"overlap\"])\n",
    "\n",
    "        num_classes = len(encoder.classes_)\n",
    "        feat_dim = data[0].shape[1]\n",
    "        labels_dim = labels.shape\n",
    "        print(f\"The shape of data is {data.shape}, the feat_dim is {feat_dim}, the labels_dim is {labels_dim}\")\n",
    "\n",
    "        eyegaze_data_loader = (limu_prepare_mixed_data_loader\n",
    "                               (config, data, labels, batch_size=config[\"general\"][\"batch_size\"],\n",
    "                                max_len=config[\"general\"][\"window_size\"]))\n",
    "\n",
    "    elif config[\"general\"][\"test_mode\"] == \"One_out\":\n",
    "        train_data, train_labels, test_data, test_labels, encoder = (load_one_out_data\n",
    "                                                                     (window_size=config[\"general\"][\"window_size\"],\n",
    "                                                                      overlap=config[\"general\"][\"overlap\"]))\n",
    "\n",
    "        num_classes = len(encoder.classes_)\n",
    "        feat_dim = train_data[0].shape[1]\n",
    "        print(f\"The number of classes is {num_classes}, the feat_dim is {feat_dim}\")\n",
    "\n",
    "        eyegaze_data_loader = (limu_prepare_one_out_data_loader\n",
    "                               (config, train_data, train_labels, test_data, test_labels,\n",
    "                                batch_size=config[\"general\"][\"batch_size\"],\n",
    "                                max_len=config[\"general\"][\"window_size\"]))\n",
    "    else:\n",
    "        print(\"Either Mixed / One_out\")\n",
    "        sys.exit()\n",
    "\n",
    "    hyperparameters = LIMU_Pretrain_Hyperparameters(config)\n",
    "    model = limu_model4pretrain(config, feat_dim)\n",
    "    loss = hyperparameters.loss\n",
    "    optimizer = hyperparameters.optimizer(model.parameters(), hyperparameters.lr, weight_decay=hyperparameters.weight_decay)\n",
    "\n",
    "    pretrain_limu_model(model, loss, optimizer, eyegaze_data_loader[0], config)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
