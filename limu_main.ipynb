{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'general': {'test_mode': 'One_out', 'window_size': 150, 'overlap': 0.8, 'pretrain_model': None, 'batch_size': 128, 'freeze': False}, 'kdd_pretrain': {'epoch': 9600, 'lr': 0.0001, 'optimizer': 'RAdam', 'weight_decay': None, 'harden': False}, 'limu_pretrain': {'epoch': 9600, 'lr': 0.0001, 'optimizer': 'Adam', 'weight_decay': None, 'harden': False}, 'limu_mask': {'mask_ratio': 0.15, 'mask_alpha': 6, 'max_gram': 10, 'mask_prob': 0.8, 'replace_prob': 0.0}, 'kdd_model': {'d_hidden': 128, 'd_ff': 256, 'n_heads': 16, 'n_layers': 3, 'dropout': 0.1, 'pos_encoding': 'learnable', 'activation': 'gelu', 'norm': 'BatchNorm', 'projection': 'linear'}, 'limu_model': {'d_hidden': 72, 'd_ff': 144, 'n_heads': 4, 'n_layers': 4, 'emb_norm': False}}\n",
      "Class: BROWSE -> Encoded Value: 0\n",
      "Class: PLAY -> Encoded Value: 1\n",
      "Class: READ -> Encoded Value: 2\n",
      "Class: SEARCH -> Encoded Value: 3\n",
      "Class: WATCH -> Encoded Value: 4\n",
      "Class: WRITE -> Encoded Value: 5\n",
      "The number of classes is 6, the feat_dim is 2\n",
      "Model:\n",
      "LIMUBertModel4Pretrain(\n",
      "  (transformer): Transformer_Original(\n",
      "    (embed): Embeddings(\n",
      "      (lin): Linear(in_features=2, out_features=72, bias=True)\n",
      "      (pos_embed): Embedding(150, 72)\n",
      "      (norm): LayerNorm()\n",
      "    )\n",
      "    (attn): MultiHeadedSelfAttention(\n",
      "      (proj_q): Linear(in_features=72, out_features=72, bias=True)\n",
      "      (proj_k): Linear(in_features=72, out_features=72, bias=True)\n",
      "      (proj_v): Linear(in_features=72, out_features=72, bias=True)\n",
      "    )\n",
      "    (proj): Linear(in_features=72, out_features=72, bias=True)\n",
      "    (norm1): LayerNorm()\n",
      "    (pwff): PositionWiseFeedForward(\n",
      "      (fc1): Linear(in_features=72, out_features=144, bias=True)\n",
      "      (fc2): Linear(in_features=144, out_features=72, bias=True)\n",
      "    )\n",
      "    (norm2): LayerNorm()\n",
      "  )\n",
      "  (fc): Linear(in_features=72, out_features=72, bias=True)\n",
      "  (linear): Linear(in_features=72, out_features=72, bias=True)\n",
      "  (norm): LayerNorm()\n",
      "  (decoder): Linear(in_features=72, out_features=2, bias=True)\n",
      ")\n",
      "Total number of parameters: 64226\n",
      "Trainable parameters: 64226\n",
      "=============================================================\n",
      "=====================Training via cuda===================\n",
      "=============================================================\n",
      "Epoch 1/9600, Train Loss: 0.0431, Time: 5.627922058105469\n",
      "Epoch 2/9600, Train Loss: 0.0067, Time: 4.926491975784302\n",
      "Epoch 3/9600, Train Loss: 0.0065, Time: 4.944820880889893\n",
      "Epoch 4/9600, Train Loss: 0.0065, Time: 4.9589033126831055\n",
      "Epoch 5/9600, Train Loss: 0.0065, Time: 4.945589303970337\n",
      "Epoch 6/9600, Train Loss: 0.0064, Time: 4.941895008087158\n",
      "Epoch 7/9600, Train Loss: 0.0064, Time: 4.949116230010986\n",
      "Epoch 8/9600, Train Loss: 0.0064, Time: 4.9562389850616455\n",
      "Epoch 9/9600, Train Loss: 0.0064, Time: 4.952052593231201\n",
      "Epoch 10/9600, Train Loss: 0.0064, Time: 4.950778961181641\n",
      "Epoch 11/9600, Train Loss: 0.0064, Time: 4.954905033111572\n",
      "Epoch 12/9600, Train Loss: 0.0063, Time: 4.943526268005371\n",
      "Epoch 13/9600, Train Loss: 0.0064, Time: 4.9452972412109375\n",
      "Epoch 14/9600, Train Loss: 0.0063, Time: 4.936536550521851\n",
      "Epoch 15/9600, Train Loss: 0.0064, Time: 4.950425624847412\n",
      "Epoch 16/9600, Train Loss: 0.0063, Time: 4.943143606185913\n",
      "Epoch 17/9600, Train Loss: 0.0063, Time: 4.954770803451538\n",
      "Epoch 18/9600, Train Loss: 0.0063, Time: 4.953639507293701\n",
      "Epoch 19/9600, Train Loss: 0.0062, Time: 4.94852876663208\n",
      "Epoch 20/9600, Train Loss: 0.0062, Time: 4.954699754714966\n",
      "Epoch 21/9600, Train Loss: 0.0062, Time: 4.950198650360107\n",
      "Epoch 22/9600, Train Loss: 0.0062, Time: 4.955212831497192\n",
      "Epoch 23/9600, Train Loss: 0.0061, Time: 4.948372840881348\n",
      "Epoch 24/9600, Train Loss: 0.0061, Time: 4.952834844589233\n",
      "Epoch 25/9600, Train Loss: 0.0060, Time: 4.956339597702026\n",
      "Epoch 26/9600, Train Loss: 0.0060, Time: 4.951586723327637\n",
      "Epoch 27/9600, Train Loss: 0.0059, Time: 4.9660351276397705\n",
      "Epoch 28/9600, Train Loss: 0.0060, Time: 4.957990407943726\n",
      "Epoch 29/9600, Train Loss: 0.0060, Time: 4.95844292640686\n",
      "Epoch 30/9600, Train Loss: 0.0059, Time: 4.95195198059082\n",
      "Epoch 31/9600, Train Loss: 0.0059, Time: 4.963211536407471\n",
      "Epoch 32/9600, Train Loss: 0.0059, Time: 4.951555967330933\n",
      "Epoch 33/9600, Train Loss: 0.0059, Time: 4.965675354003906\n",
      "Epoch 34/9600, Train Loss: 0.0060, Time: 4.9614574909210205\n",
      "Epoch 35/9600, Train Loss: 0.0060, Time: 4.963796854019165\n",
      "Epoch 36/9600, Train Loss: 0.0058, Time: 4.9607555866241455\n",
      "Epoch 37/9600, Train Loss: 0.0060, Time: 4.958337306976318\n",
      "Epoch 38/9600, Train Loss: 0.0059, Time: 4.9702441692352295\n",
      "Epoch 39/9600, Train Loss: 0.0060, Time: 4.96166205406189\n",
      "Epoch 40/9600, Train Loss: 0.0060, Time: 4.962433576583862\n",
      "Epoch 41/9600, Train Loss: 0.0060, Time: 4.956206798553467\n",
      "Epoch 42/9600, Train Loss: 0.0059, Time: 4.966416835784912\n",
      "Epoch 43/9600, Train Loss: 0.0059, Time: 4.955677509307861\n",
      "Epoch 44/9600, Train Loss: 0.0059, Time: 4.951508522033691\n",
      "Epoch 45/9600, Train Loss: 0.0059, Time: 4.954355955123901\n",
      "Epoch 46/9600, Train Loss: 0.0059, Time: 4.9571449756622314\n",
      "Epoch 47/9600, Train Loss: 0.0059, Time: 4.96243691444397\n",
      "Epoch 48/9600, Train Loss: 0.0059, Time: 4.962724924087524\n",
      "Epoch 49/9600, Train Loss: 0.0059, Time: 4.963892698287964\n",
      "Epoch 50/9600, Train Loss: 0.0060, Time: 4.956742286682129\n",
      "Epoch 51/9600, Train Loss: 0.0059, Time: 4.957281589508057\n",
      "Epoch 52/9600, Train Loss: 0.0059, Time: 4.952004432678223\n",
      "Epoch 53/9600, Train Loss: 0.0058, Time: 4.957142353057861\n",
      "Epoch 54/9600, Train Loss: 0.0059, Time: 4.95117712020874\n",
      "Epoch 55/9600, Train Loss: 0.0059, Time: 4.940950632095337\n",
      "Epoch 56/9600, Train Loss: 0.0058, Time: 4.945699691772461\n",
      "Epoch 57/9600, Train Loss: 0.0058, Time: 4.953253746032715\n",
      "Epoch 58/9600, Train Loss: 0.0059, Time: 4.959218502044678\n",
      "Epoch 59/9600, Train Loss: 0.0060, Time: 4.9542341232299805\n",
      "Epoch 60/9600, Train Loss: 0.0059, Time: 4.964540004730225\n",
      "Epoch 61/9600, Train Loss: 0.0058, Time: 4.964129686355591\n",
      "Epoch 62/9600, Train Loss: 0.0059, Time: 4.960347652435303\n",
      "Epoch 63/9600, Train Loss: 0.0059, Time: 4.964198589324951\n",
      "Epoch 64/9600, Train Loss: 0.0059, Time: 4.9571826457977295\n",
      "Epoch 65/9600, Train Loss: 0.0059, Time: 4.961507081985474\n",
      "Epoch 66/9600, Train Loss: 0.0059, Time: 4.953747034072876\n",
      "Epoch 67/9600, Train Loss: 0.0059, Time: 4.963539123535156\n",
      "Epoch 68/9600, Train Loss: 0.0058, Time: 4.955832242965698\n",
      "Epoch 69/9600, Train Loss: 0.0058, Time: 4.962465047836304\n",
      "Epoch 70/9600, Train Loss: 0.0058, Time: 4.952094316482544\n",
      "Epoch 71/9600, Train Loss: 0.0059, Time: 4.955556154251099\n",
      "Epoch 72/9600, Train Loss: 0.0058, Time: 4.965534925460815\n",
      "Epoch 73/9600, Train Loss: 0.0058, Time: 4.954042196273804\n",
      "Epoch 74/9600, Train Loss: 0.0058, Time: 4.957536935806274\n",
      "Epoch 103/9600, Train Loss: 0.0058, Time: 4.959316730499268\n",
      "Epoch 104/9600, Train Loss: 0.0058, Time: 4.954318284988403\n",
      "Epoch 105/9600, Train Loss: 0.0057, Time: 4.964817762374878\n",
      "Epoch 106/9600, Train Loss: 0.0058, Time: 4.970157623291016\n",
      "Epoch 107/9600, Train Loss: 0.0057, Time: 4.990007400512695\n",
      "Epoch 108/9600, Train Loss: 0.0058, Time: 4.975374698638916\n",
      "Epoch 109/9600, Train Loss: 0.0058, Time: 4.981501340866089\n",
      "Epoch 110/9600, Train Loss: 0.0058, Time: 4.979132652282715\n",
      "Epoch 111/9600, Train Loss: 0.0057, Time: 4.976473331451416\n",
      "Epoch 112/9600, Train Loss: 0.0057, Time: 4.969500303268433\n",
      "Epoch 113/9600, Train Loss: 0.0057, Time: 4.959370851516724\n",
      "Epoch 114/9600, Train Loss: 0.0057, Time: 4.966634511947632\n",
      "Epoch 115/9600, Train Loss: 0.0057, Time: 4.959097385406494\n",
      "Epoch 116/9600, Train Loss: 0.0058, Time: 4.968857526779175\n",
      "Epoch 117/9600, Train Loss: 0.0057, Time: 4.951110124588013\n",
      "Epoch 118/9600, Train Loss: 0.0059, Time: 4.957490921020508\n",
      "Epoch 119/9600, Train Loss: 0.0057, Time: 4.954186201095581\n",
      "Epoch 120/9600, Train Loss: 0.0058, Time: 4.966231107711792\n",
      "Epoch 121/9600, Train Loss: 0.0057, Time: 4.950040578842163\n",
      "Epoch 122/9600, Train Loss: 0.0058, Time: 4.958614110946655\n",
      "Epoch 123/9600, Train Loss: 0.0057, Time: 4.951298475265503\n",
      "Epoch 124/9600, Train Loss: 0.0058, Time: 4.953831195831299\n",
      "Epoch 125/9600, Train Loss: 0.0057, Time: 4.958052158355713\n",
      "Epoch 126/9600, Train Loss: 0.0057, Time: 4.96204400062561\n",
      "Epoch 127/9600, Train Loss: 0.0057, Time: 4.957788467407227\n",
      "Epoch 128/9600, Train Loss: 0.0057, Time: 4.962937355041504\n",
      "Epoch 129/9600, Train Loss: 0.0058, Time: 4.959619522094727\n",
      "Epoch 130/9600, Train Loss: 0.0058, Time: 4.954918384552002\n",
      "Epoch 131/9600, Train Loss: 0.0057, Time: 4.958078145980835\n",
      "Epoch 132/9600, Train Loss: 0.0057, Time: 4.951714277267456\n",
      "Epoch 133/9600, Train Loss: 0.0057, Time: 4.966834545135498\n",
      "Epoch 134/9600, Train Loss: 0.0057, Time: 4.952489614486694\n",
      "Epoch 135/9600, Train Loss: 0.0057, Time: 4.944974184036255\n",
      "Epoch 136/9600, Train Loss: 0.0058, Time: 4.960010051727295\n",
      "Epoch 137/9600, Train Loss: 0.0057, Time: 4.948414325714111\n",
      "Epoch 138/9600, Train Loss: 0.0057, Time: 4.955042839050293\n",
      "Epoch 139/9600, Train Loss: 0.0057, Time: 4.943268060684204\n",
      "Epoch 140/9600, Train Loss: 0.0057, Time: 4.953015327453613\n",
      "Epoch 141/9600, Train Loss: 0.0057, Time: 4.965207815170288\n",
      "Epoch 142/9600, Train Loss: 0.0058, Time: 4.96743106842041\n",
      "Epoch 143/9600, Train Loss: 0.0057, Time: 4.971529245376587\n",
      "Epoch 144/9600, Train Loss: 0.0057, Time: 4.971259117126465\n",
      "Epoch 145/9600, Train Loss: 0.0057, Time: 4.966176986694336\n",
      "Epoch 146/9600, Train Loss: 0.0058, Time: 4.971261262893677\n",
      "Epoch 147/9600, Train Loss: 0.0057, Time: 4.967436075210571\n",
      "Epoch 148/9600, Train Loss: 0.0057, Time: 4.959962368011475\n",
      "Epoch 149/9600, Train Loss: 0.0057, Time: 4.960324764251709\n",
      "Epoch 150/9600, Train Loss: 0.0057, Time: 4.958098649978638\n",
      "Epoch 151/9600, Train Loss: 0.0057, Time: 4.954172134399414\n",
      "Epoch 152/9600, Train Loss: 0.0057, Time: 4.958735466003418\n",
      "Epoch 153/9600, Train Loss: 0.0056, Time: 4.961784362792969\n",
      "Epoch 154/9600, Train Loss: 0.0057, Time: 4.95141863822937\n",
      "Epoch 155/9600, Train Loss: 0.0057, Time: 4.958535671234131\n",
      "Epoch 156/9600, Train Loss: 0.0057, Time: 4.969610929489136\n",
      "Epoch 157/9600, Train Loss: 0.0056, Time: 4.972662687301636\n",
      "Epoch 158/9600, Train Loss: 0.0057, Time: 4.969353914260864\n",
      "Epoch 159/9600, Train Loss: 0.0057, Time: 4.971477508544922\n",
      "Epoch 160/9600, Train Loss: 0.0057, Time: 4.9607813358306885\n",
      "Epoch 161/9600, Train Loss: 0.0057, Time: 4.965777635574341\n",
      "Epoch 162/9600, Train Loss: 0.0058, Time: 4.962784767150879\n",
      "Epoch 163/9600, Train Loss: 0.0056, Time: 4.9567954540252686\n",
      "Epoch 164/9600, Train Loss: 0.0057, Time: 4.961028337478638\n",
      "Epoch 165/9600, Train Loss: 0.0057, Time: 4.957379579544067\n",
      "Epoch 166/9600, Train Loss: 0.0057, Time: 4.956255912780762\n",
      "Epoch 167/9600, Train Loss: 0.0057, Time: 4.962024688720703\n",
      "Epoch 168/9600, Train Loss: 0.0056, Time: 4.957997560501099\n",
      "Epoch 169/9600, Train Loss: 0.0057, Time: 4.971370458602905\n",
      "Epoch 170/9600, Train Loss: 0.0057, Time: 4.9763078689575195\n",
      "Epoch 171/9600, Train Loss: 0.0057, Time: 4.9673590660095215\n",
      "Epoch 172/9600, Train Loss: 0.0057, Time: 4.973840951919556\n",
      "Epoch 173/9600, Train Loss: 0.0058, Time: 4.957372188568115\n",
      "Epoch 174/9600, Train Loss: 0.0056, Time: 4.974223613739014\n",
      "Epoch 175/9600, Train Loss: 0.0057, Time: 4.9722373485565186\n",
      "Epoch 176/9600, Train Loss: 0.0057, Time: 4.963245630264282\n",
      "Epoch 177/9600, Train Loss: 0.0057, Time: 4.961063385009766\n",
      "Epoch 178/9600, Train Loss: 0.0057, Time: 4.962484121322632\n",
      "Epoch 179/9600, Train Loss: 0.0056, Time: 4.95399022102356\n",
      "Epoch 180/9600, Train Loss: 0.0057, Time: 4.959091663360596\n",
      "Epoch 181/9600, Train Loss: 0.0057, Time: 4.956290245056152\n",
      "Epoch 182/9600, Train Loss: 0.0056, Time: 4.955852746963501\n",
      "Epoch 183/9600, Train Loss: 0.0056, Time: 4.962779760360718\n",
      "Epoch 184/9600, Train Loss: 0.0057, Time: 4.971663951873779\n",
      "Epoch 185/9600, Train Loss: 0.0056, Time: 4.966857433319092\n",
      "Epoch 186/9600, Train Loss: 0.0057, Time: 4.955805063247681\n",
      "Epoch 187/9600, Train Loss: 0.0056, Time: 4.961108207702637\n",
      "Epoch 188/9600, Train Loss: 0.0057, Time: 4.970679521560669\n",
      "Epoch 189/9600, Train Loss: 0.0057, Time: 4.972227573394775\n",
      "Epoch 190/9600, Train Loss: 0.0057, Time: 4.951856374740601\n",
      "Epoch 191/9600, Train Loss: 0.0057, Time: 4.966424226760864\n",
      "Epoch 192/9600, Train Loss: 0.0056, Time: 4.962146282196045\n",
      "Epoch 193/9600, Train Loss: 0.0057, Time: 4.95808219909668\n",
      "Epoch 194/9600, Train Loss: 0.0056, Time: 4.954426050186157\n",
      "Epoch 195/9600, Train Loss: 0.0056, Time: 4.953642129898071\n",
      "Epoch 196/9600, Train Loss: 0.0056, Time: 4.957839250564575\n",
      "Epoch 197/9600, Train Loss: 0.0057, Time: 4.963697671890259\n",
      "Epoch 198/9600, Train Loss: 0.0057, Time: 4.9716637134552\n",
      "Epoch 199/9600, Train Loss: 0.0057, Time: 4.950636386871338\n",
      "Epoch 200/9600, Train Loss: 0.0056, Time: 4.958358287811279\n",
      "Epoch 201/9600, Train Loss: 0.0057, Time: 4.956860065460205\n",
      "Epoch 202/9600, Train Loss: 0.0057, Time: 4.967144966125488\n",
      "Epoch 203/9600, Train Loss: 0.0057, Time: 4.97409725189209\n",
      "Epoch 204/9600, Train Loss: 0.0057, Time: 4.9765002727508545\n",
      "Epoch 205/9600, Train Loss: 0.0057, Time: 4.984030723571777\n",
      "Epoch 206/9600, Train Loss: 0.0057, Time: 4.953699827194214\n",
      "Epoch 207/9600, Train Loss: 0.0057, Time: 4.96417498588562\n",
      "Epoch 208/9600, Train Loss: 0.0057, Time: 4.965397834777832\n",
      "Epoch 209/9600, Train Loss: 0.0056, Time: 4.954700946807861\n",
      "Epoch 210/9600, Train Loss: 0.0056, Time: 4.969766139984131\n",
      "Epoch 211/9600, Train Loss: 0.0057, Time: 4.959595203399658\n",
      "Epoch 212/9600, Train Loss: 0.0057, Time: 4.967427015304565\n",
      "Epoch 213/9600, Train Loss: 0.0057, Time: 4.9557764530181885\n",
      "Epoch 214/9600, Train Loss: 0.0057, Time: 4.960901260375977\n",
      "Epoch 215/9600, Train Loss: 0.0057, Time: 4.952960014343262\n",
      "Epoch 216/9600, Train Loss: 0.0057, Time: 4.965721130371094\n",
      "Epoch 217/9600, Train Loss: 0.0057, Time: 4.956691741943359\n",
      "Epoch 218/9600, Train Loss: 0.0056, Time: 4.957260370254517\n",
      "Epoch 219/9600, Train Loss: 0.0056, Time: 4.966423511505127\n",
      "Epoch 220/9600, Train Loss: 0.0056, Time: 4.963001012802124\n",
      "Epoch 221/9600, Train Loss: 0.0056, Time: 4.9497389793396\n",
      "Epoch 222/9600, Train Loss: 0.0056, Time: 4.962366819381714\n",
      "Epoch 223/9600, Train Loss: 0.0057, Time: 4.956269025802612\n",
      "Epoch 224/9600, Train Loss: 0.0056, Time: 4.9545111656188965\n",
      "Epoch 225/9600, Train Loss: 0.0057, Time: 4.956675052642822\n",
      "Epoch 226/9600, Train Loss: 0.0057, Time: 4.958361625671387\n",
      "Epoch 227/9600, Train Loss: 0.0057, Time: 4.965544700622559\n",
      "Epoch 228/9600, Train Loss: 0.0057, Time: 4.965655088424683\n",
      "Epoch 229/9600, Train Loss: 0.0057, Time: 4.969785213470459\n",
      "Epoch 230/9600, Train Loss: 0.0056, Time: 4.977067470550537\n",
      "Epoch 231/9600, Train Loss: 0.0057, Time: 4.966331481933594\n",
      "Epoch 232/9600, Train Loss: 0.0057, Time: 4.964773178100586\n",
      "Epoch 233/9600, Train Loss: 0.0057, Time: 4.969437599182129\n",
      "Epoch 234/9600, Train Loss: 0.0057, Time: 4.9603047370910645\n",
      "Epoch 235/9600, Train Loss: 0.0056, Time: 4.971865892410278\n",
      "Epoch 236/9600, Train Loss: 0.0056, Time: 4.961674928665161\n",
      "Epoch 237/9600, Train Loss: 0.0056, Time: 4.949873685836792\n",
      "Epoch 238/9600, Train Loss: 0.0056, Time: 4.954472541809082\n",
      "Epoch 239/9600, Train Loss: 0.0057, Time: 4.952929496765137\n",
      "Epoch 240/9600, Train Loss: 0.0057, Time: 4.957056760787964\n",
      "Epoch 241/9600, Train Loss: 0.0057, Time: 4.956694841384888\n",
      "Epoch 242/9600, Train Loss: 0.0057, Time: 4.9601380825042725\n",
      "Epoch 243/9600, Train Loss: 0.0056, Time: 4.964747428894043\n",
      "Epoch 244/9600, Train Loss: 0.0058, Time: 4.960936784744263\n",
      "Epoch 245/9600, Train Loss: 0.0056, Time: 4.978876113891602\n",
      "Epoch 246/9600, Train Loss: 0.0056, Time: 4.971082925796509\n",
      "Epoch 247/9600, Train Loss: 0.0057, Time: 4.9667909145355225\n",
      "Epoch 248/9600, Train Loss: 0.0056, Time: 4.9772467613220215\n",
      "Epoch 249/9600, Train Loss: 0.0057, Time: 4.971697092056274\n",
      "Epoch 250/9600, Train Loss: 0.0057, Time: 4.964485168457031\n",
      "Epoch 251/9600, Train Loss: 0.0057, Time: 4.9684576988220215\n",
      "Epoch 252/9600, Train Loss: 0.0056, Time: 4.95373797416687\n",
      "Epoch 253/9600, Train Loss: 0.0057, Time: 4.949192762374878\n",
      "Epoch 254/9600, Train Loss: 0.0056, Time: 4.958625078201294\n",
      "Epoch 255/9600, Train Loss: 0.0056, Time: 4.946859836578369\n",
      "Epoch 256/9600, Train Loss: 0.0057, Time: 4.954580068588257\n",
      "Epoch 257/9600, Train Loss: 0.0056, Time: 4.962661981582642\n",
      "Epoch 258/9600, Train Loss: 0.0057, Time: 4.969720125198364\n",
      "Epoch 259/9600, Train Loss: 0.0056, Time: 4.964514493942261\n",
      "Epoch 260/9600, Train Loss: 0.0057, Time: 4.971992015838623\n",
      "Epoch 261/9600, Train Loss: 0.0057, Time: 4.964587211608887\n",
      "Epoch 262/9600, Train Loss: 0.0057, Time: 4.965404033660889\n",
      "Epoch 263/9600, Train Loss: 0.0057, Time: 4.967348575592041\n",
      "Epoch 264/9600, Train Loss: 0.0057, Time: 4.9696831703186035\n",
      "Epoch 265/9600, Train Loss: 0.0057, Time: 4.981281518936157\n",
      "Epoch 266/9600, Train Loss: 0.0057, Time: 4.960779428482056\n",
      "Epoch 267/9600, Train Loss: 0.0056, Time: 4.957412958145142\n",
      "Epoch 268/9600, Train Loss: 0.0056, Time: 4.95721173286438\n",
      "Epoch 269/9600, Train Loss: 0.0057, Time: 4.959489822387695\n",
      "Epoch 270/9600, Train Loss: 0.0056, Time: 4.960775852203369\n",
      "Epoch 271/9600, Train Loss: 0.0056, Time: 4.967364072799683\n",
      "Epoch 272/9600, Train Loss: 0.0056, Time: 4.954070806503296\n",
      "Epoch 273/9600, Train Loss: 0.0057, Time: 4.966806173324585\n",
      "Epoch 274/9600, Train Loss: 0.0057, Time: 4.960820913314819\n",
      "Epoch 275/9600, Train Loss: 0.0057, Time: 4.958199501037598\n",
      "Epoch 276/9600, Train Loss: 0.0056, Time: 4.956137657165527\n",
      "Epoch 277/9600, Train Loss: 0.0056, Time: 4.971001386642456\n",
      "Epoch 278/9600, Train Loss: 0.0056, Time: 4.970844030380249\n",
      "Epoch 279/9600, Train Loss: 0.0056, Time: 4.96660852432251\n",
      "Epoch 280/9600, Train Loss: 0.0056, Time: 4.964977025985718\n",
      "Epoch 281/9600, Train Loss: 0.0056, Time: 4.967724800109863\n",
      "Epoch 282/9600, Train Loss: 0.0057, Time: 4.962579250335693\n",
      "Epoch 283/9600, Train Loss: 0.0057, Time: 4.941359281539917\n",
      "Epoch 284/9600, Train Loss: 0.0057, Time: 4.950086355209351\n",
      "Epoch 285/9600, Train Loss: 0.0056, Time: 4.957156658172607\n",
      "Epoch 286/9600, Train Loss: 0.0056, Time: 4.953552484512329\n",
      "Epoch 287/9600, Train Loss: 0.0057, Time: 4.946798801422119\n",
      "Epoch 288/9600, Train Loss: 0.0057, Time: 4.955174207687378\n",
      "Epoch 289/9600, Train Loss: 0.0057, Time: 4.9607908725738525\n",
      "Epoch 290/9600, Train Loss: 0.0056, Time: 4.965384483337402\n",
      "Epoch 291/9600, Train Loss: 0.0057, Time: 4.961643695831299\n",
      "Epoch 292/9600, Train Loss: 0.0056, Time: 4.959432125091553\n",
      "Epoch 293/9600, Train Loss: 0.0057, Time: 4.969813585281372\n",
      "Epoch 294/9600, Train Loss: 0.0057, Time: 4.9708333015441895\n",
      "Epoch 295/9600, Train Loss: 0.0057, Time: 4.969409704208374\n",
      "Epoch 296/9600, Train Loss: 0.0057, Time: 4.962571382522583\n",
      "Epoch 297/9600, Train Loss: 0.0056, Time: 4.973470449447632\n",
      "Epoch 298/9600, Train Loss: 0.0056, Time: 4.962608575820923\n",
      "Epoch 299/9600, Train Loss: 0.0056, Time: 4.965843200683594\n",
      "Epoch 300/9600, Train Loss: 0.0056, Time: 4.957081079483032\n",
      "Epoch 301/9600, Train Loss: 0.0056, Time: 4.957176446914673\n",
      "Epoch 302/9600, Train Loss: 0.0056, Time: 4.9550559520721436\n",
      "Epoch 303/9600, Train Loss: 0.0056, Time: 4.95827579498291\n",
      "Epoch 304/9600, Train Loss: 0.0056, Time: 4.957878351211548\n",
      "Epoch 305/9600, Train Loss: 0.0056, Time: 4.954947471618652\n",
      "Epoch 306/9600, Train Loss: 0.0057, Time: 4.970016002655029\n",
      "Epoch 307/9600, Train Loss: 0.0057, Time: 4.971698522567749\n",
      "Epoch 308/9600, Train Loss: 0.0056, Time: 4.961129188537598\n",
      "Epoch 309/9600, Train Loss: 0.0056, Time: 4.974855899810791\n",
      "Epoch 310/9600, Train Loss: 0.0057, Time: 4.97186017036438\n",
      "Epoch 311/9600, Train Loss: 0.0056, Time: 4.952571153640747\n",
      "Epoch 312/9600, Train Loss: 0.0057, Time: 4.957273244857788\n",
      "Epoch 313/9600, Train Loss: 0.0056, Time: 4.9595606327056885\n",
      "Epoch 314/9600, Train Loss: 0.0057, Time: 4.95510721206665\n",
      "Epoch 315/9600, Train Loss: 0.0057, Time: 4.960744380950928\n",
      "Epoch 316/9600, Train Loss: 0.0056, Time: 4.953456401824951\n",
      "Epoch 317/9600, Train Loss: 0.0057, Time: 4.9557414054870605\n",
      "Epoch 318/9600, Train Loss: 0.0057, Time: 4.95866847038269\n",
      "Epoch 319/9600, Train Loss: 0.0056, Time: 4.960397243499756\n",
      "Epoch 320/9600, Train Loss: 0.0057, Time: 4.9621782302856445\n",
      "Epoch 321/9600, Train Loss: 0.0057, Time: 4.966108083724976\n",
      "Epoch 322/9600, Train Loss: 0.0057, Time: 4.956816673278809\n",
      "Epoch 323/9600, Train Loss: 0.0057, Time: 4.967651128768921\n",
      "Epoch 324/9600, Train Loss: 0.0056, Time: 4.947311639785767\n",
      "Epoch 325/9600, Train Loss: 0.0056, Time: 4.974558353424072\n",
      "Epoch 326/9600, Train Loss: 0.0057, Time: 4.966292142868042\n",
      "Epoch 327/9600, Train Loss: 0.0057, Time: 4.970190763473511\n",
      "Epoch 328/9600, Train Loss: 0.0057, Time: 4.965185642242432\n",
      "Epoch 329/9600, Train Loss: 0.0057, Time: 4.9540112018585205\n",
      "Epoch 330/9600, Train Loss: 0.0056, Time: 4.970367670059204\n",
      "Epoch 331/9600, Train Loss: 0.0056, Time: 4.967494249343872\n",
      "Epoch 332/9600, Train Loss: 0.0056, Time: 4.951105356216431\n",
      "Epoch 333/9600, Train Loss: 0.0057, Time: 4.957530736923218\n",
      "Epoch 334/9600, Train Loss: 0.0056, Time: 4.958108186721802\n",
      "Epoch 335/9600, Train Loss: 0.0057, Time: 4.9574854373931885\n",
      "Epoch 336/9600, Train Loss: 0.0057, Time: 4.951796054840088\n",
      "Epoch 337/9600, Train Loss: 0.0057, Time: 4.964951038360596\n",
      "Epoch 338/9600, Train Loss: 0.0056, Time: 4.960604667663574\n",
      "Epoch 339/9600, Train Loss: 0.0056, Time: 4.960373163223267\n",
      "Epoch 340/9600, Train Loss: 0.0056, Time: 4.967226266860962\n",
      "Epoch 341/9600, Train Loss: 0.0057, Time: 4.961096525192261\n",
      "Epoch 342/9600, Train Loss: 0.0057, Time: 4.972331523895264\n",
      "Epoch 343/9600, Train Loss: 0.0056, Time: 4.9648778438568115\n",
      "Epoch 344/9600, Train Loss: 0.0057, Time: 4.9642493724823\n",
      "Epoch 345/9600, Train Loss: 0.0056, Time: 4.977700471878052\n",
      "Epoch 346/9600, Train Loss: 0.0056, Time: 4.97202467918396\n",
      "Epoch 347/9600, Train Loss: 0.0056, Time: 4.976217746734619\n",
      "Epoch 348/9600, Train Loss: 0.0056, Time: 4.958358526229858\n",
      "Epoch 349/9600, Train Loss: 0.0056, Time: 4.9590699672698975\n",
      "Epoch 350/9600, Train Loss: 0.0056, Time: 4.9707841873168945\n",
      "Epoch 351/9600, Train Loss: 0.0056, Time: 4.967555046081543\n",
      "Epoch 352/9600, Train Loss: 0.0057, Time: 4.965296983718872\n",
      "Epoch 353/9600, Train Loss: 0.0057, Time: 4.948877334594727\n",
      "Epoch 354/9600, Train Loss: 0.0056, Time: 4.972286224365234\n",
      "Epoch 355/9600, Train Loss: 0.0056, Time: 4.963104248046875\n",
      "Epoch 356/9600, Train Loss: 0.0056, Time: 4.9750282764434814\n",
      "Epoch 357/9600, Train Loss: 0.0057, Time: 4.967274188995361\n",
      "Epoch 358/9600, Train Loss: 0.0056, Time: 4.971909761428833\n",
      "Epoch 359/9600, Train Loss: 0.0057, Time: 4.971295118331909\n",
      "Epoch 360/9600, Train Loss: 0.0057, Time: 4.958571434020996\n",
      "Epoch 361/9600, Train Loss: 0.0056, Time: 4.972353458404541\n",
      "Epoch 362/9600, Train Loss: 0.0056, Time: 4.969650983810425\n",
      "Epoch 363/9600, Train Loss: 0.0057, Time: 4.9717535972595215\n",
      "Epoch 364/9600, Train Loss: 0.0056, Time: 4.962673187255859\n",
      "Epoch 365/9600, Train Loss: 0.0057, Time: 4.946671485900879\n",
      "Epoch 366/9600, Train Loss: 0.0056, Time: 4.954523801803589\n",
      "Epoch 367/9600, Train Loss: 0.0056, Time: 4.951296091079712\n",
      "Epoch 368/9600, Train Loss: 0.0056, Time: 4.9553587436676025\n",
      "Epoch 369/9600, Train Loss: 0.0056, Time: 4.9533610343933105\n",
      "Epoch 370/9600, Train Loss: 0.0056, Time: 4.9578986167907715\n",
      "Epoch 371/9600, Train Loss: 0.0056, Time: 4.964818000793457\n",
      "Epoch 372/9600, Train Loss: 0.0056, Time: 4.960815906524658\n",
      "Epoch 373/9600, Train Loss: 0.0056, Time: 4.961609840393066\n",
      "Epoch 374/9600, Train Loss: 0.0057, Time: 4.96673059463501\n",
      "Epoch 375/9600, Train Loss: 0.0056, Time: 4.961506128311157\n",
      "Epoch 376/9600, Train Loss: 0.0056, Time: 4.963822603225708\n",
      "Epoch 377/9600, Train Loss: 0.0056, Time: 4.9679107666015625\n",
      "Epoch 378/9600, Train Loss: 0.0057, Time: 4.966324329376221\n",
      "Epoch 379/9600, Train Loss: 0.0056, Time: 4.97289514541626\n",
      "Epoch 380/9600, Train Loss: 0.0056, Time: 4.9620020389556885\n",
      "Epoch 381/9600, Train Loss: 0.0056, Time: 4.968456745147705\n",
      "Epoch 382/9600, Train Loss: 0.0056, Time: 4.952971935272217\n",
      "Epoch 383/9600, Train Loss: 0.0056, Time: 4.955157995223999\n",
      "Epoch 384/9600, Train Loss: 0.0056, Time: 4.9632978439331055\n",
      "Epoch 385/9600, Train Loss: 0.0057, Time: 4.956478118896484\n",
      "Epoch 386/9600, Train Loss: 0.0056, Time: 4.963512420654297\n",
      "Epoch 387/9600, Train Loss: 0.0056, Time: 4.9612085819244385\n",
      "Epoch 388/9600, Train Loss: 0.0056, Time: 4.958534002304077\n",
      "Epoch 389/9600, Train Loss: 0.0056, Time: 4.965179443359375\n",
      "Epoch 390/9600, Train Loss: 0.0057, Time: 4.968526363372803\n",
      "Epoch 391/9600, Train Loss: 0.0056, Time: 4.971757173538208\n",
      "Epoch 392/9600, Train Loss: 0.0056, Time: 4.962761640548706\n",
      "Epoch 393/9600, Train Loss: 0.0056, Time: 4.957791566848755\n",
      "Epoch 394/9600, Train Loss: 0.0056, Time: 4.971211671829224\n",
      "Epoch 395/9600, Train Loss: 0.0057, Time: 4.967010498046875\n",
      "Epoch 396/9600, Train Loss: 0.0056, Time: 4.967111587524414\n",
      "Epoch 397/9600, Train Loss: 0.0056, Time: 4.95903754234314\n",
      "Epoch 398/9600, Train Loss: 0.0056, Time: 4.959634065628052\n",
      "Epoch 399/9600, Train Loss: 0.0056, Time: 4.961460828781128\n",
      "Epoch 400/9600, Train Loss: 0.0055, Time: 4.953294277191162\n",
      "Epoch 401/9600, Train Loss: 0.0056, Time: 4.958112955093384\n",
      "Epoch 402/9600, Train Loss: 0.0056, Time: 4.961523532867432\n",
      "Epoch 403/9600, Train Loss: 0.0055, Time: 4.956197023391724\n",
      "Epoch 404/9600, Train Loss: 0.0056, Time: 4.9683003425598145\n",
      "Epoch 405/9600, Train Loss: 0.0056, Time: 4.96496057510376\n",
      "Epoch 406/9600, Train Loss: 0.0056, Time: 4.9643707275390625\n",
      "Epoch 407/9600, Train Loss: 0.0056, Time: 4.961138963699341\n",
      "Epoch 408/9600, Train Loss: 0.0055, Time: 4.971923589706421\n",
      "Epoch 409/9600, Train Loss: 0.0056, Time: 4.956367015838623\n",
      "Epoch 410/9600, Train Loss: 0.0056, Time: 4.965806007385254\n",
      "Epoch 411/9600, Train Loss: 0.0056, Time: 4.965139627456665\n",
      "Epoch 412/9600, Train Loss: 0.0056, Time: 4.948588609695435\n",
      "Epoch 413/9600, Train Loss: 0.0056, Time: 4.959487676620483\n",
      "Epoch 414/9600, Train Loss: 0.0056, Time: 4.94855260848999\n",
      "Epoch 415/9600, Train Loss: 0.0056, Time: 4.951910018920898\n",
      "Epoch 416/9600, Train Loss: 0.0056, Time: 4.954411268234253\n",
      "Epoch 417/9600, Train Loss: 0.0055, Time: 4.95691704750061\n",
      "Epoch 418/9600, Train Loss: 0.0055, Time: 4.964469909667969\n",
      "Epoch 419/9600, Train Loss: 0.0056, Time: 4.9658215045928955\n",
      "Epoch 420/9600, Train Loss: 0.0056, Time: 4.971520662307739\n",
      "Epoch 421/9600, Train Loss: 0.0055, Time: 4.959000587463379\n",
      "Epoch 422/9600, Train Loss: 0.0055, Time: 4.963559865951538\n",
      "Epoch 423/9600, Train Loss: 0.0056, Time: 4.961862564086914\n",
      "Epoch 424/9600, Train Loss: 0.0055, Time: 4.964099168777466\n",
      "Epoch 425/9600, Train Loss: 0.0056, Time: 4.954675674438477\n",
      "Epoch 426/9600, Train Loss: 0.0055, Time: 4.948639869689941\n",
      "Epoch 427/9600, Train Loss: 0.0055, Time: 4.951570749282837\n",
      "Epoch 428/9600, Train Loss: 0.0055, Time: 4.959709405899048\n",
      "Epoch 429/9600, Train Loss: 0.0055, Time: 4.9557671546936035\n",
      "Epoch 430/9600, Train Loss: 0.0055, Time: 4.950899124145508\n",
      "Epoch 431/9600, Train Loss: 0.0055, Time: 4.952679634094238\n",
      "Epoch 432/9600, Train Loss: 0.0055, Time: 4.961083173751831\n",
      "Epoch 433/9600, Train Loss: 0.0056, Time: 4.9592978954315186\n",
      "Epoch 434/9600, Train Loss: 0.0055, Time: 4.970929861068726\n",
      "Epoch 435/9600, Train Loss: 0.0056, Time: 4.969380855560303\n",
      "Epoch 436/9600, Train Loss: 0.0056, Time: 4.97163987159729\n",
      "Epoch 437/9600, Train Loss: 0.0055, Time: 4.960139751434326\n",
      "Epoch 438/9600, Train Loss: 0.0055, Time: 4.9587626457214355\n",
      "Epoch 439/9600, Train Loss: 0.0055, Time: 4.968598127365112\n",
      "Epoch 440/9600, Train Loss: 0.0055, Time: 4.968183517456055\n",
      "Epoch 441/9600, Train Loss: 0.0055, Time: 4.956465005874634\n",
      "Epoch 442/9600, Train Loss: 0.0055, Time: 4.948869705200195\n",
      "Epoch 443/9600, Train Loss: 0.0056, Time: 4.958119630813599\n",
      "Epoch 444/9600, Train Loss: 0.0056, Time: 4.958231687545776\n",
      "Epoch 445/9600, Train Loss: 0.0055, Time: 4.955685615539551\n",
      "Epoch 446/9600, Train Loss: 0.0055, Time: 4.95446252822876\n",
      "Epoch 447/9600, Train Loss: 0.0055, Time: 4.964267253875732\n",
      "Epoch 448/9600, Train Loss: 0.0055, Time: 4.959557056427002\n",
      "Epoch 449/9600, Train Loss: 0.0055, Time: 4.957347631454468\n",
      "Epoch 450/9600, Train Loss: 0.0056, Time: 4.9691162109375\n",
      "Epoch 451/9600, Train Loss: 0.0055, Time: 4.979131698608398\n",
      "Epoch 452/9600, Train Loss: 0.0055, Time: 4.964216709136963\n",
      "Epoch 453/9600, Train Loss: 0.0056, Time: 4.9606218338012695\n",
      "Epoch 454/9600, Train Loss: 0.0055, Time: 4.953763246536255\n",
      "Epoch 455/9600, Train Loss: 0.0055, Time: 4.96134614944458\n",
      "Epoch 456/9600, Train Loss: 0.0055, Time: 4.964833736419678\n",
      "Epoch 457/9600, Train Loss: 0.0056, Time: 4.956308841705322\n",
      "Epoch 458/9600, Train Loss: 0.0055, Time: 4.958394289016724\n",
      "Epoch 459/9600, Train Loss: 0.0055, Time: 4.954684495925903\n",
      "Epoch 460/9600, Train Loss: 0.0055, Time: 4.961581468582153\n",
      "Epoch 461/9600, Train Loss: 0.0055, Time: 4.953454494476318\n",
      "Epoch 462/9600, Train Loss: 0.0055, Time: 4.956636190414429\n",
      "Epoch 463/9600, Train Loss: 0.0056, Time: 4.965348958969116\n",
      "Epoch 464/9600, Train Loss: 0.0055, Time: 4.986908435821533\n",
      "Epoch 465/9600, Train Loss: 0.0055, Time: 4.980236053466797\n",
      "Epoch 466/9600, Train Loss: 0.0055, Time: 4.978090763092041\n",
      "Epoch 467/9600, Train Loss: 0.0055, Time: 4.974836826324463\n",
      "Epoch 468/9600, Train Loss: 0.0055, Time: 4.965684175491333\n",
      "Epoch 469/9600, Train Loss: 0.0054, Time: 4.964874267578125\n",
      "Epoch 470/9600, Train Loss: 0.0055, Time: 4.966141223907471\n",
      "Epoch 471/9600, Train Loss: 0.0056, Time: 4.97326922416687\n",
      "Epoch 472/9600, Train Loss: 0.0055, Time: 4.983506917953491\n",
      "Epoch 473/9600, Train Loss: 0.0055, Time: 4.972671985626221\n",
      "Epoch 474/9600, Train Loss: 0.0055, Time: 4.979351758956909\n",
      "Epoch 475/9600, Train Loss: 0.0055, Time: 4.958576917648315\n",
      "Epoch 476/9600, Train Loss: 0.0055, Time: 4.9586181640625\n",
      "Epoch 477/9600, Train Loss: 0.0055, Time: 4.948883533477783\n",
      "Epoch 478/9600, Train Loss: 0.0055, Time: 4.947843313217163\n",
      "Epoch 479/9600, Train Loss: 0.0055, Time: 4.961303472518921\n",
      "Epoch 480/9600, Train Loss: 0.0055, Time: 4.962944984436035\n",
      "Epoch 481/9600, Train Loss: 0.0055, Time: 4.98520827293396\n",
      "Epoch 482/9600, Train Loss: 0.0054, Time: 4.987425088882446\n",
      "Epoch 483/9600, Train Loss: 0.0055, Time: 4.982984304428101\n",
      "Epoch 484/9600, Train Loss: 0.0055, Time: 4.977699279785156\n",
      "Epoch 485/9600, Train Loss: 0.0055, Time: 4.966193199157715\n",
      "Epoch 486/9600, Train Loss: 0.0054, Time: 4.978558540344238\n",
      "Epoch 487/9600, Train Loss: 0.0054, Time: 4.9818174839019775\n",
      "Epoch 488/9600, Train Loss: 0.0055, Time: 4.977420330047607\n",
      "Epoch 489/9600, Train Loss: 0.0055, Time: 4.982151508331299\n",
      "Epoch 490/9600, Train Loss: 0.0054, Time: 4.986279487609863\n",
      "Epoch 491/9600, Train Loss: 0.0055, Time: 4.9768226146698\n",
      "Epoch 492/9600, Train Loss: 0.0054, Time: 4.974670648574829\n",
      "Epoch 493/9600, Train Loss: 0.0055, Time: 4.971392869949341\n",
      "Epoch 494/9600, Train Loss: 0.0054, Time: 4.959628105163574\n",
      "Epoch 495/9600, Train Loss: 0.0055, Time: 4.960515260696411\n",
      "Epoch 496/9600, Train Loss: 0.0055, Time: 4.953532695770264\n",
      "Epoch 497/9600, Train Loss: 0.0055, Time: 4.957547903060913\n",
      "Epoch 498/9600, Train Loss: 0.0055, Time: 4.96587061882019\n",
      "Epoch 499/9600, Train Loss: 0.0054, Time: 4.964941740036011\n",
      "Epoch 500/9600, Train Loss: 0.0055, Time: 4.97274923324585\n",
      "Epoch 501/9600, Train Loss: 0.0055, Time: 4.960304498672485\n",
      "Epoch 502/9600, Train Loss: 0.0054, Time: 4.964348793029785\n",
      "Epoch 503/9600, Train Loss: 0.0054, Time: 4.95721697807312\n",
      "Epoch 504/9600, Train Loss: 0.0054, Time: 4.975735664367676\n",
      "Epoch 505/9600, Train Loss: 0.0054, Time: 4.951650857925415\n",
      "Epoch 506/9600, Train Loss: 0.0054, Time: 4.966716051101685\n",
      "Epoch 507/9600, Train Loss: 0.0054, Time: 4.963636875152588\n",
      "Epoch 508/9600, Train Loss: 0.0055, Time: 4.958150386810303\n",
      "Epoch 509/9600, Train Loss: 0.0054, Time: 4.963052749633789\n",
      "Epoch 510/9600, Train Loss: 0.0054, Time: 4.954699754714966\n",
      "Epoch 511/9600, Train Loss: 0.0055, Time: 4.956273317337036\n",
      "Epoch 512/9600, Train Loss: 0.0054, Time: 4.955019235610962\n",
      "Epoch 513/9600, Train Loss: 0.0055, Time: 4.965747833251953\n",
      "Epoch 514/9600, Train Loss: 0.0055, Time: 4.971849203109741\n",
      "Epoch 515/9600, Train Loss: 0.0055, Time: 4.9655561447143555\n",
      "Epoch 516/9600, Train Loss: 0.0054, Time: 4.96755313873291\n",
      "Epoch 517/9600, Train Loss: 0.0054, Time: 4.969574451446533\n",
      "Epoch 518/9600, Train Loss: 0.0054, Time: 4.9693732261657715\n",
      "Epoch 519/9600, Train Loss: 0.0054, Time: 4.965029239654541\n",
      "Epoch 520/9600, Train Loss: 0.0054, Time: 4.959593772888184\n",
      "Epoch 521/9600, Train Loss: 0.0054, Time: 4.967806577682495\n",
      "Epoch 522/9600, Train Loss: 0.0054, Time: 4.963035583496094\n",
      "Epoch 523/9600, Train Loss: 0.0054, Time: 4.9543914794921875\n",
      "Epoch 524/9600, Train Loss: 0.0053, Time: 4.95537257194519\n",
      "Epoch 525/9600, Train Loss: 0.0054, Time: 4.956096172332764\n",
      "Epoch 526/9600, Train Loss: 0.0055, Time: 4.9488255977630615\n",
      "Epoch 527/9600, Train Loss: 0.0054, Time: 4.9530744552612305\n",
      "Epoch 528/9600, Train Loss: 0.0054, Time: 4.96960186958313\n",
      "Epoch 529/9600, Train Loss: 0.0054, Time: 4.967832803726196\n",
      "Epoch 530/9600, Train Loss: 0.0054, Time: 4.956532955169678\n",
      "Epoch 531/9600, Train Loss: 0.0055, Time: 4.970627069473267\n",
      "Epoch 532/9600, Train Loss: 0.0054, Time: 4.966137409210205\n",
      "Epoch 533/9600, Train Loss: 0.0054, Time: 4.967308282852173\n",
      "Epoch 534/9600, Train Loss: 0.0054, Time: 4.962811708450317\n",
      "Epoch 535/9600, Train Loss: 0.0053, Time: 4.960891485214233\n",
      "Epoch 536/9600, Train Loss: 0.0054, Time: 4.969573974609375\n",
      "Epoch 537/9600, Train Loss: 0.0054, Time: 4.9749815464019775\n",
      "Epoch 538/9600, Train Loss: 0.0054, Time: 4.961000680923462\n",
      "Epoch 539/9600, Train Loss: 0.0054, Time: 4.956640720367432\n",
      "Epoch 540/9600, Train Loss: 0.0054, Time: 4.967633485794067\n",
      "Epoch 541/9600, Train Loss: 0.0054, Time: 4.956929683685303\n",
      "Epoch 542/9600, Train Loss: 0.0053, Time: 4.9641876220703125\n",
      "Epoch 543/9600, Train Loss: 0.0054, Time: 4.971575498580933\n",
      "Epoch 544/9600, Train Loss: 0.0054, Time: 4.965281963348389\n",
      "Epoch 545/9600, Train Loss: 0.0055, Time: 4.967664480209351\n",
      "Epoch 546/9600, Train Loss: 0.0054, Time: 4.960311651229858\n",
      "Epoch 547/9600, Train Loss: 0.0054, Time: 4.952142715454102\n",
      "Epoch 548/9600, Train Loss: 0.0054, Time: 4.97124171257019\n",
      "Epoch 549/9600, Train Loss: 0.0054, Time: 4.977635622024536\n",
      "Epoch 550/9600, Train Loss: 0.0054, Time: 4.957890748977661\n",
      "Epoch 551/9600, Train Loss: 0.0054, Time: 4.960770606994629\n",
      "Epoch 552/9600, Train Loss: 0.0054, Time: 4.9847283363342285\n",
      "Epoch 553/9600, Train Loss: 0.0054, Time: 4.95948052406311\n",
      "Epoch 554/9600, Train Loss: 0.0054, Time: 4.957812547683716\n",
      "Epoch 555/9600, Train Loss: 0.0054, Time: 4.960087537765503\n",
      "Epoch 556/9600, Train Loss: 0.0055, Time: 4.963177919387817\n",
      "Epoch 557/9600, Train Loss: 0.0054, Time: 4.965591192245483\n",
      "Epoch 558/9600, Train Loss: 0.0054, Time: 4.964220762252808\n",
      "Epoch 559/9600, Train Loss: 0.0054, Time: 4.9636993408203125\n",
      "Epoch 560/9600, Train Loss: 0.0054, Time: 4.978346824645996\n",
      "Epoch 561/9600, Train Loss: 0.0054, Time: 4.9734532833099365\n",
      "Epoch 562/9600, Train Loss: 0.0054, Time: 4.959709167480469\n",
      "Epoch 563/9600, Train Loss: 0.0053, Time: 4.962881326675415\n",
      "Epoch 564/9600, Train Loss: 0.0054, Time: 4.961411476135254\n",
      "Epoch 565/9600, Train Loss: 0.0054, Time: 4.965399503707886\n",
      "Epoch 566/9600, Train Loss: 0.0054, Time: 4.9570817947387695\n",
      "Epoch 567/9600, Train Loss: 0.0054, Time: 4.973754405975342\n",
      "Epoch 568/9600, Train Loss: 0.0054, Time: 4.961095333099365\n",
      "Epoch 569/9600, Train Loss: 0.0053, Time: 4.977689266204834\n",
      "Epoch 570/9600, Train Loss: 0.0054, Time: 4.9702067375183105\n",
      "Epoch 571/9600, Train Loss: 0.0053, Time: 4.972965240478516\n",
      "Epoch 572/9600, Train Loss: 0.0054, Time: 4.969925165176392\n",
      "Epoch 573/9600, Train Loss: 0.0053, Time: 4.973485708236694\n",
      "Epoch 574/9600, Train Loss: 0.0053, Time: 4.969875812530518\n",
      "Epoch 575/9600, Train Loss: 0.0054, Time: 4.967380046844482\n",
      "Epoch 576/9600, Train Loss: 0.0054, Time: 4.952650785446167\n",
      "Epoch 577/9600, Train Loss: 0.0054, Time: 4.956743240356445\n",
      "Epoch 578/9600, Train Loss: 0.0054, Time: 4.962648153305054\n",
      "Epoch 579/9600, Train Loss: 0.0053, Time: 4.955084562301636\n",
      "Epoch 580/9600, Train Loss: 0.0054, Time: 4.9540112018585205\n",
      "Epoch 581/9600, Train Loss: 0.0054, Time: 4.958829402923584\n",
      "Epoch 582/9600, Train Loss: 0.0054, Time: 4.970492601394653\n",
      "Epoch 583/9600, Train Loss: 0.0054, Time: 4.965245723724365\n",
      "Epoch 584/9600, Train Loss: 0.0053, Time: 4.9611265659332275\n",
      "Epoch 585/9600, Train Loss: 0.0053, Time: 4.967417478561401\n",
      "Epoch 586/9600, Train Loss: 0.0053, Time: 4.96787691116333\n",
      "Epoch 587/9600, Train Loss: 0.0054, Time: 4.976394891738892\n",
      "Epoch 588/9600, Train Loss: 0.0054, Time: 4.96147084236145\n",
      "Epoch 589/9600, Train Loss: 0.0053, Time: 4.967934846878052\n",
      "Epoch 590/9600, Train Loss: 0.0054, Time: 4.966456890106201\n",
      "Epoch 591/9600, Train Loss: 0.0054, Time: 4.9544360637664795\n",
      "Epoch 592/9600, Train Loss: 0.0054, Time: 4.980679512023926\n",
      "Epoch 593/9600, Train Loss: 0.0054, Time: 4.963897705078125\n",
      "Epoch 594/9600, Train Loss: 0.0053, Time: 4.965202808380127\n",
      "Epoch 595/9600, Train Loss: 0.0054, Time: 4.957516670227051\n",
      "Epoch 596/9600, Train Loss: 0.0054, Time: 4.966362476348877\n",
      "Epoch 597/9600, Train Loss: 0.0054, Time: 4.9637579917907715\n",
      "Epoch 598/9600, Train Loss: 0.0053, Time: 4.960332632064819\n",
      "Epoch 599/9600, Train Loss: 0.0053, Time: 4.970869302749634\n",
      "Epoch 600/9600, Train Loss: 0.0053, Time: 4.9744203090667725\n",
      "Epoch 601/9600, Train Loss: 0.0053, Time: 4.973228693008423\n",
      "Epoch 602/9600, Train Loss: 0.0054, Time: 4.964207410812378\n",
      "Epoch 603/9600, Train Loss: 0.0054, Time: 4.970928192138672\n",
      "Epoch 604/9600, Train Loss: 0.0054, Time: 4.9624199867248535\n",
      "Epoch 605/9600, Train Loss: 0.0054, Time: 4.964165925979614\n",
      "Epoch 606/9600, Train Loss: 0.0053, Time: 4.958200693130493\n",
      "Epoch 607/9600, Train Loss: 0.0054, Time: 4.960161924362183\n",
      "Epoch 608/9600, Train Loss: 0.0053, Time: 4.9615561962127686\n",
      "Epoch 609/9600, Train Loss: 0.0053, Time: 4.958713531494141\n",
      "Epoch 610/9600, Train Loss: 0.0053, Time: 4.960727691650391\n",
      "Epoch 611/9600, Train Loss: 0.0053, Time: 4.974199295043945\n",
      "Epoch 612/9600, Train Loss: 0.0053, Time: 4.968425035476685\n",
      "Epoch 613/9600, Train Loss: 0.0053, Time: 4.9606640338897705\n",
      "Epoch 614/9600, Train Loss: 0.0053, Time: 4.971235990524292\n",
      "Epoch 615/9600, Train Loss: 0.0053, Time: 4.966371774673462\n",
      "Epoch 616/9600, Train Loss: 0.0053, Time: 4.974775075912476\n",
      "Epoch 617/9600, Train Loss: 0.0053, Time: 4.96707558631897\n",
      "Epoch 618/9600, Train Loss: 0.0053, Time: 4.96860671043396\n",
      "Epoch 619/9600, Train Loss: 0.0053, Time: 4.960726022720337\n",
      "Epoch 620/9600, Train Loss: 0.0053, Time: 4.955005407333374\n",
      "Epoch 621/9600, Train Loss: 0.0053, Time: 4.957162857055664\n",
      "Epoch 622/9600, Train Loss: 0.0053, Time: 4.960999011993408\n",
      "Epoch 623/9600, Train Loss: 0.0053, Time: 4.958517789840698\n",
      "Epoch 624/9600, Train Loss: 0.0053, Time: 4.971010446548462\n",
      "Epoch 625/9600, Train Loss: 0.0053, Time: 4.972779273986816\n",
      "Epoch 626/9600, Train Loss: 0.0053, Time: 4.974682807922363\n",
      "Epoch 627/9600, Train Loss: 0.0053, Time: 4.973607301712036\n",
      "Epoch 628/9600, Train Loss: 0.0053, Time: 4.969238042831421\n",
      "Epoch 629/9600, Train Loss: 0.0053, Time: 4.967179536819458\n",
      "Epoch 630/9600, Train Loss: 0.0053, Time: 4.972904920578003\n",
      "Epoch 631/9600, Train Loss: 0.0053, Time: 4.967409610748291\n",
      "Epoch 632/9600, Train Loss: 0.0052, Time: 4.98095703125\n",
      "Epoch 633/9600, Train Loss: 0.0052, Time: 4.956697702407837\n",
      "Epoch 634/9600, Train Loss: 0.0053, Time: 4.959496259689331\n",
      "Epoch 635/9600, Train Loss: 0.0053, Time: 4.958865642547607\n",
      "Epoch 636/9600, Train Loss: 0.0053, Time: 4.952974557876587\n",
      "Epoch 637/9600, Train Loss: 0.0053, Time: 4.957525014877319\n",
      "Epoch 638/9600, Train Loss: 0.0053, Time: 4.949237823486328\n",
      "Epoch 639/9600, Train Loss: 0.0053, Time: 4.960462331771851\n",
      "Epoch 640/9600, Train Loss: 0.0053, Time: 4.974675178527832\n",
      "Epoch 641/9600, Train Loss: 0.0053, Time: 4.966729402542114\n",
      "Epoch 642/9600, Train Loss: 0.0053, Time: 4.970542669296265\n",
      "Epoch 643/9600, Train Loss: 0.0053, Time: 4.969486236572266\n",
      "Epoch 644/9600, Train Loss: 0.0053, Time: 4.969198942184448\n",
      "Epoch 645/9600, Train Loss: 0.0053, Time: 4.964521169662476\n",
      "Epoch 646/9600, Train Loss: 0.0053, Time: 4.968765735626221\n",
      "Epoch 647/9600, Train Loss: 0.0053, Time: 4.955362558364868\n",
      "Epoch 648/9600, Train Loss: 0.0053, Time: 4.955461025238037\n",
      "Epoch 649/9600, Train Loss: 0.0053, Time: 4.953242063522339\n",
      "Epoch 650/9600, Train Loss: 0.0052, Time: 4.959018230438232\n",
      "Epoch 651/9600, Train Loss: 0.0052, Time: 4.949417591094971\n",
      "Epoch 652/9600, Train Loss: 0.0052, Time: 4.952358722686768\n",
      "Epoch 653/9600, Train Loss: 0.0053, Time: 4.96319055557251\n",
      "Epoch 654/9600, Train Loss: 0.0053, Time: 4.973664045333862\n",
      "Epoch 655/9600, Train Loss: 0.0052, Time: 4.967772006988525\n",
      "Epoch 656/9600, Train Loss: 0.0052, Time: 4.966441631317139\n",
      "Epoch 657/9600, Train Loss: 0.0053, Time: 4.976527452468872\n",
      "Epoch 658/9600, Train Loss: 0.0053, Time: 4.973768711090088\n",
      "Epoch 659/9600, Train Loss: 0.0053, Time: 4.97435450553894\n",
      "Epoch 660/9600, Train Loss: 0.0053, Time: 4.96081805229187\n",
      "Epoch 661/9600, Train Loss: 0.0053, Time: 4.975461721420288\n",
      "Epoch 662/9600, Train Loss: 0.0053, Time: 4.963337659835815\n",
      "Epoch 663/9600, Train Loss: 0.0053, Time: 4.962244749069214\n",
      "Epoch 664/9600, Train Loss: 0.0052, Time: 4.956138372421265\n",
      "Epoch 665/9600, Train Loss: 0.0053, Time: 4.960927486419678\n",
      "Epoch 666/9600, Train Loss: 0.0053, Time: 4.956141233444214\n",
      "Epoch 667/9600, Train Loss: 0.0053, Time: 4.950069427490234\n",
      "Epoch 668/9600, Train Loss: 0.0053, Time: 4.965890407562256\n",
      "Epoch 669/9600, Train Loss: 0.0053, Time: 4.9791176319122314\n",
      "Epoch 670/9600, Train Loss: 0.0053, Time: 4.978757619857788\n",
      "Epoch 671/9600, Train Loss: 0.0052, Time: 4.975207328796387\n",
      "Epoch 672/9600, Train Loss: 0.0053, Time: 4.972502708435059\n",
      "Epoch 673/9600, Train Loss: 0.0053, Time: 4.971954822540283\n",
      "Epoch 674/9600, Train Loss: 0.0053, Time: 4.965779066085815\n",
      "Epoch 675/9600, Train Loss: 0.0053, Time: 4.9657628536224365\n",
      "Epoch 676/9600, Train Loss: 0.0052, Time: 4.978086709976196\n",
      "Epoch 677/9600, Train Loss: 0.0052, Time: 4.965578079223633\n",
      "Epoch 678/9600, Train Loss: 0.0052, Time: 4.970562219619751\n",
      "Epoch 679/9600, Train Loss: 0.0053, Time: 4.963996171951294\n",
      "Epoch 680/9600, Train Loss: 0.0052, Time: 4.971112966537476\n",
      "Epoch 681/9600, Train Loss: 0.0053, Time: 4.968015670776367\n",
      "Epoch 682/9600, Train Loss: 0.0053, Time: 4.971230983734131\n",
      "Epoch 683/9600, Train Loss: 0.0052, Time: 4.964516878128052\n",
      "Epoch 684/9600, Train Loss: 0.0052, Time: 4.962597131729126\n",
      "Epoch 685/9600, Train Loss: 0.0053, Time: 4.967863082885742\n",
      "Epoch 686/9600, Train Loss: 0.0053, Time: 4.967885494232178\n",
      "Epoch 687/9600, Train Loss: 0.0053, Time: 4.957978010177612\n",
      "Epoch 688/9600, Train Loss: 0.0052, Time: 4.978448390960693\n",
      "Epoch 689/9600, Train Loss: 0.0052, Time: 4.969830751419067\n",
      "Epoch 690/9600, Train Loss: 0.0053, Time: 4.9685797691345215\n",
      "Epoch 691/9600, Train Loss: 0.0053, Time: 4.962738990783691\n",
      "Epoch 692/9600, Train Loss: 0.0052, Time: 4.959978342056274\n",
      "Epoch 693/9600, Train Loss: 0.0053, Time: 4.971971273422241\n",
      "Epoch 694/9600, Train Loss: 0.0053, Time: 4.963905334472656\n",
      "Epoch 695/9600, Train Loss: 0.0052, Time: 4.962113857269287\n",
      "Epoch 696/9600, Train Loss: 0.0053, Time: 4.972771644592285\n",
      "Epoch 697/9600, Train Loss: 0.0052, Time: 4.972202777862549\n",
      "Epoch 698/9600, Train Loss: 0.0053, Time: 4.95596170425415\n",
      "Epoch 699/9600, Train Loss: 0.0053, Time: 4.9699296951293945\n",
      "Epoch 700/9600, Train Loss: 0.0053, Time: 4.971611738204956\n",
      "Epoch 701/9600, Train Loss: 0.0053, Time: 4.964668035507202\n",
      "Epoch 702/9600, Train Loss: 0.0052, Time: 4.964622735977173\n",
      "Epoch 703/9600, Train Loss: 0.0052, Time: 4.974294662475586\n",
      "Epoch 704/9600, Train Loss: 0.0053, Time: 4.971261739730835\n",
      "Epoch 705/9600, Train Loss: 0.0053, Time: 4.953096151351929\n",
      "Epoch 706/9600, Train Loss: 0.0053, Time: 4.971003293991089\n",
      "Epoch 707/9600, Train Loss: 0.0052, Time: 4.965226173400879\n",
      "Epoch 708/9600, Train Loss: 0.0052, Time: 4.965941905975342\n",
      "Epoch 709/9600, Train Loss: 0.0053, Time: 4.965129137039185\n",
      "Epoch 710/9600, Train Loss: 0.0053, Time: 4.9620771408081055\n",
      "Epoch 711/9600, Train Loss: 0.0053, Time: 4.966784715652466\n",
      "Epoch 712/9600, Train Loss: 0.0053, Time: 4.969985246658325\n",
      "Epoch 713/9600, Train Loss: 0.0053, Time: 4.993999719619751\n",
      "Epoch 714/9600, Train Loss: 0.0052, Time: 4.989448308944702\n",
      "Epoch 715/9600, Train Loss: 0.0052, Time: 4.958647966384888\n",
      "Epoch 716/9600, Train Loss: 0.0052, Time: 4.968639612197876\n",
      "Epoch 717/9600, Train Loss: 0.0052, Time: 4.968110084533691\n",
      "Epoch 718/9600, Train Loss: 0.0052, Time: 4.972338676452637\n",
      "Epoch 719/9600, Train Loss: 0.0052, Time: 4.964874029159546\n",
      "Epoch 720/9600, Train Loss: 0.0053, Time: 4.96119236946106\n",
      "Epoch 721/9600, Train Loss: 0.0053, Time: 4.9532692432403564\n",
      "Epoch 722/9600, Train Loss: 0.0053, Time: 4.961025238037109\n",
      "Epoch 723/9600, Train Loss: 0.0052, Time: 4.961969614028931\n",
      "Epoch 724/9600, Train Loss: 0.0053, Time: 4.951403617858887\n",
      "Epoch 725/9600, Train Loss: 0.0052, Time: 4.956072092056274\n",
      "Epoch 726/9600, Train Loss: 0.0052, Time: 4.961423873901367\n",
      "Epoch 727/9600, Train Loss: 0.0052, Time: 4.95596981048584\n",
      "Epoch 728/9600, Train Loss: 0.0052, Time: 4.966668605804443\n",
      "Epoch 729/9600, Train Loss: 0.0053, Time: 4.96115779876709\n",
      "Epoch 730/9600, Train Loss: 0.0053, Time: 4.958172798156738\n",
      "Epoch 731/9600, Train Loss: 0.0052, Time: 4.969195127487183\n",
      "Epoch 732/9600, Train Loss: 0.0052, Time: 4.962662696838379\n",
      "Epoch 733/9600, Train Loss: 0.0052, Time: 4.9688944816589355\n",
      "Epoch 734/9600, Train Loss: 0.0052, Time: 4.958351135253906\n",
      "Epoch 735/9600, Train Loss: 0.0052, Time: 4.965636253356934\n",
      "Epoch 736/9600, Train Loss: 0.0053, Time: 4.971812963485718\n",
      "Epoch 737/9600, Train Loss: 0.0053, Time: 4.956066846847534\n",
      "Epoch 738/9600, Train Loss: 0.0053, Time: 4.953390598297119\n",
      "Epoch 739/9600, Train Loss: 0.0052, Time: 4.959290981292725\n",
      "Epoch 740/9600, Train Loss: 0.0053, Time: 4.952656269073486\n",
      "Epoch 741/9600, Train Loss: 0.0053, Time: 4.951190948486328\n",
      "Epoch 742/9600, Train Loss: 0.0052, Time: 4.96353006362915\n",
      "Epoch 743/9600, Train Loss: 0.0052, Time: 4.969707012176514\n",
      "Epoch 744/9600, Train Loss: 0.0052, Time: 4.970879316329956\n",
      "Epoch 745/9600, Train Loss: 0.0052, Time: 4.964659214019775\n",
      "Epoch 746/9600, Train Loss: 0.0052, Time: 4.984594106674194\n",
      "Epoch 747/9600, Train Loss: 0.0052, Time: 4.960980653762817\n",
      "Epoch 748/9600, Train Loss: 0.0053, Time: 4.973942518234253\n",
      "Epoch 749/9600, Train Loss: 0.0052, Time: 4.97775936126709\n",
      "Epoch 750/9600, Train Loss: 0.0052, Time: 4.97123384475708\n",
      "Epoch 751/9600, Train Loss: 0.0053, Time: 4.970144748687744\n",
      "Epoch 752/9600, Train Loss: 0.0052, Time: 4.952024698257446\n",
      "Epoch 753/9600, Train Loss: 0.0052, Time: 4.96384072303772\n",
      "Epoch 754/9600, Train Loss: 0.0052, Time: 4.963559150695801\n",
      "Epoch 755/9600, Train Loss: 0.0052, Time: 4.96143913269043\n",
      "Epoch 756/9600, Train Loss: 0.0053, Time: 4.96554970741272\n",
      "Epoch 757/9600, Train Loss: 0.0052, Time: 4.966017484664917\n",
      "Epoch 758/9600, Train Loss: 0.0052, Time: 4.959507703781128\n",
      "Epoch 759/9600, Train Loss: 0.0052, Time: 4.9648027420043945\n",
      "Epoch 760/9600, Train Loss: 0.0052, Time: 4.965234041213989\n",
      "Epoch 761/9600, Train Loss: 0.0053, Time: 4.972813367843628\n",
      "Epoch 762/9600, Train Loss: 0.0052, Time: 4.982633829116821\n",
      "Epoch 763/9600, Train Loss: 0.0052, Time: 4.957633018493652\n",
      "Epoch 764/9600, Train Loss: 0.0052, Time: 4.962641000747681\n",
      "Epoch 765/9600, Train Loss: 0.0052, Time: 4.951196193695068\n",
      "Epoch 766/9600, Train Loss: 0.0052, Time: 4.958603143692017\n",
      "Epoch 767/9600, Train Loss: 0.0052, Time: 4.9622602462768555\n",
      "Epoch 768/9600, Train Loss: 0.0052, Time: 4.95929741859436\n",
      "Epoch 769/9600, Train Loss: 0.0052, Time: 4.9684059619903564\n",
      "Epoch 770/9600, Train Loss: 0.0053, Time: 4.957832336425781\n",
      "Epoch 771/9600, Train Loss: 0.0053, Time: 4.971004962921143\n",
      "Epoch 772/9600, Train Loss: 0.0052, Time: 4.970810413360596\n",
      "Epoch 773/9600, Train Loss: 0.0053, Time: 4.9726903438568115\n",
      "Epoch 774/9600, Train Loss: 0.0052, Time: 4.976221799850464\n",
      "Epoch 775/9600, Train Loss: 0.0052, Time: 4.979040622711182\n",
      "Epoch 776/9600, Train Loss: 0.0052, Time: 4.972465991973877\n",
      "Epoch 777/9600, Train Loss: 0.0053, Time: 4.965343236923218\n",
      "Epoch 778/9600, Train Loss: 0.0053, Time: 4.966286897659302\n",
      "Epoch 779/9600, Train Loss: 0.0052, Time: 4.9665422439575195\n",
      "Epoch 780/9600, Train Loss: 0.0052, Time: 4.965515851974487\n",
      "Epoch 781/9600, Train Loss: 0.0052, Time: 4.965585947036743\n",
      "Epoch 782/9600, Train Loss: 0.0052, Time: 4.967495441436768\n",
      "Epoch 783/9600, Train Loss: 0.0052, Time: 4.965190649032593\n",
      "Epoch 784/9600, Train Loss: 0.0052, Time: 4.962188959121704\n",
      "Epoch 785/9600, Train Loss: 0.0052, Time: 4.96321964263916\n",
      "Epoch 786/9600, Train Loss: 0.0052, Time: 4.970052719116211\n",
      "Epoch 787/9600, Train Loss: 0.0052, Time: 4.972241401672363\n",
      "Epoch 788/9600, Train Loss: 0.0052, Time: 4.96323299407959\n",
      "Epoch 789/9600, Train Loss: 0.0052, Time: 4.963383674621582\n",
      "Epoch 790/9600, Train Loss: 0.0052, Time: 4.953343868255615\n",
      "Epoch 791/9600, Train Loss: 0.0052, Time: 4.969861745834351\n",
      "Epoch 792/9600, Train Loss: 0.0053, Time: 4.970167636871338\n",
      "Epoch 793/9600, Train Loss: 0.0052, Time: 4.968104124069214\n",
      "Epoch 794/9600, Train Loss: 0.0052, Time: 4.967550039291382\n",
      "Epoch 795/9600, Train Loss: 0.0052, Time: 4.954166650772095\n",
      "Epoch 796/9600, Train Loss: 0.0052, Time: 4.9579176902771\n",
      "Epoch 797/9600, Train Loss: 0.0052, Time: 4.9587767124176025\n",
      "Epoch 798/9600, Train Loss: 0.0052, Time: 4.961248397827148\n",
      "Epoch 799/9600, Train Loss: 0.0052, Time: 4.960843801498413\n",
      "Epoch 800/9600, Train Loss: 0.0052, Time: 4.952225685119629\n",
      "Epoch 801/9600, Train Loss: 0.0053, Time: 4.9569642543792725\n",
      "Epoch 802/9600, Train Loss: 0.0052, Time: 4.962064504623413\n",
      "Epoch 803/9600, Train Loss: 0.0052, Time: 4.972706317901611\n",
      "Epoch 804/9600, Train Loss: 0.0052, Time: 4.96802282333374\n",
      "Epoch 805/9600, Train Loss: 0.0052, Time: 4.965933322906494\n",
      "Epoch 806/9600, Train Loss: 0.0052, Time: 4.972163438796997\n",
      "Epoch 807/9600, Train Loss: 0.0052, Time: 4.9596569538116455\n",
      "Epoch 808/9600, Train Loss: 0.0052, Time: 4.96530818939209\n",
      "Epoch 809/9600, Train Loss: 0.0052, Time: 4.967997312545776\n",
      "Epoch 810/9600, Train Loss: 0.0052, Time: 4.9691009521484375\n",
      "Epoch 811/9600, Train Loss: 0.0052, Time: 4.966141223907471\n",
      "Epoch 812/9600, Train Loss: 0.0052, Time: 4.9648284912109375\n",
      "Epoch 813/9600, Train Loss: 0.0052, Time: 4.9620819091796875\n",
      "Epoch 814/9600, Train Loss: 0.0052, Time: 4.965701103210449\n",
      "Epoch 815/9600, Train Loss: 0.0052, Time: 4.973788499832153\n",
      "Epoch 816/9600, Train Loss: 0.0053, Time: 4.966228723526001\n",
      "Epoch 817/9600, Train Loss: 0.0052, Time: 4.968882322311401\n",
      "Epoch 818/9600, Train Loss: 0.0052, Time: 4.960238218307495\n",
      "Epoch 819/9600, Train Loss: 0.0052, Time: 4.98026967048645\n",
      "Epoch 820/9600, Train Loss: 0.0052, Time: 4.961118936538696\n",
      "Epoch 821/9600, Train Loss: 0.0052, Time: 4.969827175140381\n",
      "Epoch 822/9600, Train Loss: 0.0052, Time: 4.971823453903198\n",
      "Epoch 823/9600, Train Loss: 0.0051, Time: 4.975106954574585\n",
      "Epoch 824/9600, Train Loss: 0.0052, Time: 4.975013017654419\n",
      "Epoch 825/9600, Train Loss: 0.0052, Time: 4.967664003372192\n",
      "Epoch 826/9600, Train Loss: 0.0053, Time: 4.972615957260132\n",
      "Epoch 827/9600, Train Loss: 0.0052, Time: 4.970188856124878\n",
      "Epoch 828/9600, Train Loss: 0.0052, Time: 4.965192794799805\n",
      "Epoch 829/9600, Train Loss: 0.0052, Time: 4.966679573059082\n",
      "Epoch 830/9600, Train Loss: 0.0052, Time: 4.9573705196380615\n",
      "Epoch 831/9600, Train Loss: 0.0052, Time: 4.956857442855835\n",
      "Epoch 832/9600, Train Loss: 0.0052, Time: 4.957936763763428\n",
      "Epoch 833/9600, Train Loss: 0.0052, Time: 4.956174373626709\n",
      "Epoch 834/9600, Train Loss: 0.0052, Time: 4.9662394523620605\n",
      "Epoch 835/9600, Train Loss: 0.0052, Time: 4.967365026473999\n",
      "Epoch 836/9600, Train Loss: 0.0052, Time: 4.966786623001099\n",
      "Epoch 837/9600, Train Loss: 0.0052, Time: 4.960381984710693\n",
      "Epoch 838/9600, Train Loss: 0.0052, Time: 4.95501446723938\n",
      "Epoch 839/9600, Train Loss: 0.0052, Time: 4.957218647003174\n",
      "Epoch 840/9600, Train Loss: 0.0052, Time: 4.963123083114624\n",
      "Epoch 841/9600, Train Loss: 0.0052, Time: 4.953522682189941\n",
      "Epoch 842/9600, Train Loss: 0.0052, Time: 4.967841863632202\n",
      "Epoch 843/9600, Train Loss: 0.0051, Time: 4.9619460105896\n",
      "Epoch 844/9600, Train Loss: 0.0051, Time: 4.973896503448486\n",
      "Epoch 845/9600, Train Loss: 0.0051, Time: 4.965677261352539\n",
      "Epoch 846/9600, Train Loss: 0.0052, Time: 4.963770151138306\n",
      "Epoch 847/9600, Train Loss: 0.0052, Time: 4.961032867431641\n",
      "Epoch 848/9600, Train Loss: 0.0052, Time: 4.965264797210693\n",
      "Epoch 849/9600, Train Loss: 0.0052, Time: 4.958453178405762\n",
      "Epoch 850/9600, Train Loss: 0.0052, Time: 4.970398664474487\n",
      "Epoch 851/9600, Train Loss: 0.0052, Time: 4.969632148742676\n",
      "Epoch 852/9600, Train Loss: 0.0052, Time: 4.967750787734985\n",
      "Epoch 853/9600, Train Loss: 0.0052, Time: 4.974231958389282\n",
      "Epoch 854/9600, Train Loss: 0.0052, Time: 4.976279973983765\n",
      "Epoch 855/9600, Train Loss: 0.0052, Time: 4.975687265396118\n",
      "Epoch 856/9600, Train Loss: 0.0052, Time: 5.024130821228027\n",
      "Epoch 857/9600, Train Loss: 0.0052, Time: 4.963435649871826\n",
      "Epoch 858/9600, Train Loss: 0.0052, Time: 4.973731279373169\n",
      "Epoch 859/9600, Train Loss: 0.0052, Time: 4.96186637878418\n",
      "Epoch 860/9600, Train Loss: 0.0052, Time: 4.959942579269409\n",
      "Epoch 861/9600, Train Loss: 0.0052, Time: 4.955293893814087\n",
      "Epoch 862/9600, Train Loss: 0.0051, Time: 4.959679126739502\n",
      "Epoch 863/9600, Train Loss: 0.0052, Time: 4.976903676986694\n",
      "Epoch 864/9600, Train Loss: 0.0052, Time: 4.974323511123657\n",
      "Epoch 865/9600, Train Loss: 0.0052, Time: 4.97852087020874\n",
      "Epoch 866/9600, Train Loss: 0.0053, Time: 4.9620726108551025\n",
      "Epoch 867/9600, Train Loss: 0.0052, Time: 4.978312015533447\n",
      "Epoch 868/9600, Train Loss: 0.0052, Time: 4.97217059135437\n",
      "Epoch 869/9600, Train Loss: 0.0051, Time: 4.9701313972473145\n",
      "Epoch 870/9600, Train Loss: 0.0052, Time: 4.967697858810425\n",
      "Epoch 871/9600, Train Loss: 0.0051, Time: 4.9762327671051025\n",
      "Epoch 872/9600, Train Loss: 0.0052, Time: 4.9762609004974365\n",
      "Epoch 873/9600, Train Loss: 0.0052, Time: 4.9714367389678955\n",
      "Epoch 874/9600, Train Loss: 0.0052, Time: 4.965271234512329\n",
      "Epoch 875/9600, Train Loss: 0.0051, Time: 4.975620985031128\n",
      "Epoch 876/9600, Train Loss: 0.0052, Time: 4.9717042446136475\n",
      "Epoch 877/9600, Train Loss: 0.0052, Time: 4.965108156204224\n",
      "Epoch 878/9600, Train Loss: 0.0052, Time: 4.963077545166016\n",
      "Epoch 879/9600, Train Loss: 0.0052, Time: 4.979074716567993\n",
      "Epoch 880/9600, Train Loss: 0.0052, Time: 4.9737303256988525\n",
      "Epoch 881/9600, Train Loss: 0.0052, Time: 4.95840311050415\n",
      "Epoch 882/9600, Train Loss: 0.0052, Time: 4.971426725387573\n",
      "Epoch 883/9600, Train Loss: 0.0051, Time: 4.971781492233276\n",
      "Epoch 884/9600, Train Loss: 0.0052, Time: 4.97079610824585\n",
      "Epoch 885/9600, Train Loss: 0.0052, Time: 4.965716600418091\n",
      "Epoch 886/9600, Train Loss: 0.0052, Time: 4.962878704071045\n",
      "Epoch 887/9600, Train Loss: 0.0052, Time: 4.969362497329712\n",
      "Epoch 888/9600, Train Loss: 0.0052, Time: 4.964337348937988\n",
      "Epoch 889/9600, Train Loss: 0.0051, Time: 4.970734596252441\n",
      "Epoch 890/9600, Train Loss: 0.0052, Time: 4.973215103149414\n",
      "Epoch 891/9600, Train Loss: 0.0051, Time: 4.962195158004761\n",
      "Epoch 892/9600, Train Loss: 0.0051, Time: 4.966549873352051\n",
      "Epoch 893/9600, Train Loss: 0.0052, Time: 4.968693256378174\n",
      "Epoch 894/9600, Train Loss: 0.0052, Time: 4.972676038742065\n",
      "Epoch 895/9600, Train Loss: 0.0052, Time: 4.971109390258789\n",
      "Epoch 896/9600, Train Loss: 0.0052, Time: 4.962098121643066\n",
      "Epoch 897/9600, Train Loss: 0.0052, Time: 4.973603963851929\n",
      "Epoch 898/9600, Train Loss: 0.0052, Time: 4.9604175090789795\n",
      "Epoch 899/9600, Train Loss: 0.0052, Time: 4.980593919754028\n",
      "Epoch 900/9600, Train Loss: 0.0052, Time: 4.965862274169922\n",
      "Epoch 901/9600, Train Loss: 0.0052, Time: 4.967775583267212\n",
      "Epoch 902/9600, Train Loss: 0.0052, Time: 4.9767231941223145\n",
      "Epoch 903/9600, Train Loss: 0.0052, Time: 4.962391138076782\n",
      "Epoch 904/9600, Train Loss: 0.0053, Time: 4.961910963058472\n",
      "Epoch 905/9600, Train Loss: 0.0052, Time: 4.963569641113281\n",
      "Epoch 906/9600, Train Loss: 0.0052, Time: 4.957818031311035\n",
      "Epoch 907/9600, Train Loss: 0.0052, Time: 4.95749306678772\n",
      "Epoch 908/9600, Train Loss: 0.0052, Time: 4.969768285751343\n",
      "Epoch 909/9600, Train Loss: 0.0052, Time: 4.9785072803497314\n",
      "Epoch 910/9600, Train Loss: 0.0052, Time: 4.971619606018066\n",
      "Epoch 911/9600, Train Loss: 0.0052, Time: 4.9733359813690186\n",
      "Epoch 912/9600, Train Loss: 0.0051, Time: 4.969179630279541\n",
      "Epoch 913/9600, Train Loss: 0.0052, Time: 4.9761505126953125\n",
      "Epoch 914/9600, Train Loss: 0.0051, Time: 4.986385345458984\n",
      "Epoch 915/9600, Train Loss: 0.0052, Time: 4.974041700363159\n",
      "Epoch 916/9600, Train Loss: 0.0052, Time: 4.966875076293945\n",
      "Epoch 917/9600, Train Loss: 0.0051, Time: 4.97074556350708\n",
      "Epoch 918/9600, Train Loss: 0.0052, Time: 4.986483097076416\n",
      "Epoch 919/9600, Train Loss: 0.0052, Time: 4.9826202392578125\n",
      "Epoch 920/9600, Train Loss: 0.0052, Time: 4.965747117996216\n",
      "Epoch 921/9600, Train Loss: 0.0052, Time: 4.985334157943726\n",
      "Epoch 922/9600, Train Loss: 0.0051, Time: 4.9653520584106445\n",
      "Epoch 923/9600, Train Loss: 0.0051, Time: 4.977318525314331\n",
      "Epoch 924/9600, Train Loss: 0.0052, Time: 4.974766969680786\n",
      "Epoch 925/9600, Train Loss: 0.0052, Time: 4.965923309326172\n",
      "Epoch 926/9600, Train Loss: 0.0051, Time: 4.962238073348999\n",
      "Epoch 927/9600, Train Loss: 0.0052, Time: 4.975660800933838\n",
      "Epoch 928/9600, Train Loss: 0.0052, Time: 4.958698511123657\n",
      "Epoch 929/9600, Train Loss: 0.0051, Time: 4.967904567718506\n",
      "Epoch 930/9600, Train Loss: 0.0051, Time: 4.958747863769531\n",
      "Epoch 931/9600, Train Loss: 0.0051, Time: 4.964902639389038\n",
      "Epoch 932/9600, Train Loss: 0.0052, Time: 4.964420318603516\n",
      "Epoch 933/9600, Train Loss: 0.0052, Time: 4.961138010025024\n",
      "Epoch 934/9600, Train Loss: 0.0052, Time: 4.955824613571167\n",
      "Epoch 935/9600, Train Loss: 0.0051, Time: 4.975783348083496\n",
      "Epoch 936/9600, Train Loss: 0.0052, Time: 4.96796441078186\n",
      "Epoch 937/9600, Train Loss: 0.0052, Time: 4.968620300292969\n",
      "Epoch 938/9600, Train Loss: 0.0051, Time: 4.966177463531494\n",
      "Epoch 939/9600, Train Loss: 0.0052, Time: 4.970429182052612\n",
      "Epoch 940/9600, Train Loss: 0.0052, Time: 4.96785044670105\n",
      "Epoch 941/9600, Train Loss: 0.0051, Time: 4.97163200378418\n",
      "Epoch 942/9600, Train Loss: 0.0051, Time: 4.965903997421265\n",
      "Epoch 943/9600, Train Loss: 0.0051, Time: 4.96495509147644\n",
      "Epoch 944/9600, Train Loss: 0.0051, Time: 4.961876153945923\n",
      "Epoch 945/9600, Train Loss: 0.0051, Time: 4.950885772705078\n",
      "Epoch 946/9600, Train Loss: 0.0052, Time: 4.949744701385498\n",
      "Epoch 947/9600, Train Loss: 0.0052, Time: 4.953997611999512\n",
      "Epoch 948/9600, Train Loss: 0.0052, Time: 4.975191354751587\n",
      "Epoch 949/9600, Train Loss: 0.0052, Time: 4.970685958862305\n",
      "Epoch 950/9600, Train Loss: 0.0051, Time: 4.974940538406372\n",
      "Epoch 951/9600, Train Loss: 0.0052, Time: 4.971471548080444\n",
      "Epoch 952/9600, Train Loss: 0.0051, Time: 4.976651668548584\n",
      "Epoch 953/9600, Train Loss: 0.0052, Time: 4.963214874267578\n",
      "Epoch 954/9600, Train Loss: 0.0052, Time: 4.9798009395599365\n",
      "Epoch 955/9600, Train Loss: 0.0052, Time: 4.980590343475342\n",
      "Epoch 956/9600, Train Loss: 0.0051, Time: 4.973895311355591\n",
      "Epoch 957/9600, Train Loss: 0.0052, Time: 4.963693141937256\n",
      "Epoch 958/9600, Train Loss: 0.0052, Time: 4.97064471244812\n",
      "Epoch 959/9600, Train Loss: 0.0052, Time: 4.960075855255127\n",
      "Epoch 960/9600, Train Loss: 0.0052, Time: 4.97262978553772\n",
      "Epoch 961/9600, Train Loss: 0.0052, Time: 4.964178085327148\n",
      "Epoch 962/9600, Train Loss: 0.0052, Time: 4.967487096786499\n",
      "Epoch 963/9600, Train Loss: 0.0051, Time: 4.978095769882202\n",
      "Epoch 964/9600, Train Loss: 0.0052, Time: 4.9645421504974365\n",
      "Epoch 965/9600, Train Loss: 0.0052, Time: 4.979578971862793\n",
      "Epoch 966/9600, Train Loss: 0.0051, Time: 4.9741880893707275\n",
      "Epoch 967/9600, Train Loss: 0.0052, Time: 4.971463203430176\n",
      "Epoch 968/9600, Train Loss: 0.0052, Time: 4.976617336273193\n",
      "Epoch 969/9600, Train Loss: 0.0051, Time: 4.978673934936523\n",
      "Epoch 970/9600, Train Loss: 0.0051, Time: 4.977150201797485\n",
      "Epoch 971/9600, Train Loss: 0.0051, Time: 4.9646546840667725\n",
      "Epoch 972/9600, Train Loss: 0.0051, Time: 4.954755067825317\n",
      "Epoch 973/9600, Train Loss: 0.0052, Time: 4.965456008911133\n",
      "Epoch 974/9600, Train Loss: 0.0051, Time: 4.97275185585022\n",
      "Epoch 975/9600, Train Loss: 0.0051, Time: 4.969611644744873\n",
      "Epoch 976/9600, Train Loss: 0.0052, Time: 4.951574325561523\n",
      "Epoch 977/9600, Train Loss: 0.0051, Time: 4.9617674350738525\n",
      "Epoch 978/9600, Train Loss: 0.0051, Time: 4.967564344406128\n",
      "Epoch 979/9600, Train Loss: 0.0051, Time: 4.9704601764678955\n",
      "Epoch 980/9600, Train Loss: 0.0052, Time: 4.967189311981201\n",
      "Epoch 981/9600, Train Loss: 0.0052, Time: 4.969353675842285\n",
      "Epoch 982/9600, Train Loss: 0.0052, Time: 4.9668052196502686\n",
      "Epoch 983/9600, Train Loss: 0.0052, Time: 4.9610161781311035\n",
      "Epoch 984/9600, Train Loss: 0.0052, Time: 4.968820095062256\n",
      "Epoch 985/9600, Train Loss: 0.0052, Time: 4.9679718017578125\n",
      "Epoch 986/9600, Train Loss: 0.0052, Time: 4.960406064987183\n",
      "Epoch 987/9600, Train Loss: 0.0052, Time: 4.96292519569397\n",
      "Epoch 988/9600, Train Loss: 0.0051, Time: 4.961005210876465\n",
      "Epoch 989/9600, Train Loss: 0.0051, Time: 4.966703176498413\n",
      "Epoch 990/9600, Train Loss: 0.0052, Time: 4.9529314041137695\n",
      "Epoch 991/9600, Train Loss: 0.0051, Time: 4.977300405502319\n",
      "Epoch 992/9600, Train Loss: 0.0052, Time: 4.98149847984314\n",
      "Epoch 993/9600, Train Loss: 0.0052, Time: 4.970760822296143\n",
      "Epoch 994/9600, Train Loss: 0.0052, Time: 4.970264196395874\n",
      "Epoch 995/9600, Train Loss: 0.0052, Time: 4.971363306045532\n",
      "Epoch 996/9600, Train Loss: 0.0051, Time: 4.964945316314697\n",
      "Epoch 997/9600, Train Loss: 0.0052, Time: 4.972038984298706\n",
      "Epoch 998/9600, Train Loss: 0.0052, Time: 4.962673664093018\n",
      "Epoch 999/9600, Train Loss: 0.0051, Time: 4.9611780643463135\n",
      "Epoch 1000/9600, Train Loss: 0.0051, Time: 4.9489898681640625\n",
      "Epoch 1001/9600, Train Loss: 0.0051, Time: 4.950839519500732\n",
      "Epoch 1002/9600, Train Loss: 0.0052, Time: 4.956603288650513\n",
      "Epoch 1003/9600, Train Loss: 0.0052, Time: 4.949371099472046\n",
      "Epoch 1004/9600, Train Loss: 0.0051, Time: 4.9652910232543945\n",
      "Epoch 1005/9600, Train Loss: 0.0052, Time: 4.981321573257446\n",
      "Epoch 1006/9600, Train Loss: 0.0052, Time: 4.994563579559326\n",
      "Epoch 1007/9600, Train Loss: 0.0051, Time: 4.9829630851745605\n",
      "Epoch 1008/9600, Train Loss: 0.0052, Time: 4.982753038406372\n",
      "Epoch 1009/9600, Train Loss: 0.0051, Time: 4.972407817840576\n",
      "Epoch 1010/9600, Train Loss: 0.0052, Time: 4.976818084716797\n",
      "Epoch 1011/9600, Train Loss: 0.0051, Time: 4.959668397903442\n",
      "Epoch 1012/9600, Train Loss: 0.0052, Time: 4.964858531951904\n",
      "Epoch 1013/9600, Train Loss: 0.0051, Time: 4.98688530921936\n",
      "Epoch 1014/9600, Train Loss: 0.0051, Time: 4.976451396942139\n",
      "Epoch 1015/9600, Train Loss: 0.0052, Time: 4.993095636367798\n",
      "Epoch 1016/9600, Train Loss: 0.0051, Time: 4.974013805389404\n",
      "Epoch 1017/9600, Train Loss: 0.0051, Time: 4.975104808807373\n",
      "Epoch 1018/9600, Train Loss: 0.0051, Time: 4.9726691246032715\n",
      "Epoch 1019/9600, Train Loss: 0.0051, Time: 4.973055124282837\n",
      "Epoch 1020/9600, Train Loss: 0.0051, Time: 4.97418212890625\n",
      "Epoch 1021/9600, Train Loss: 0.0051, Time: 4.972669839859009\n",
      "Epoch 1022/9600, Train Loss: 0.0051, Time: 4.9655303955078125\n",
      "Epoch 1023/9600, Train Loss: 0.0052, Time: 4.957207441329956\n",
      "Epoch 1024/9600, Train Loss: 0.0051, Time: 4.956917762756348\n",
      "Epoch 1025/9600, Train Loss: 0.0051, Time: 4.966497421264648\n",
      "Epoch 1026/9600, Train Loss: 0.0052, Time: 4.9761643409729\n",
      "Epoch 1027/9600, Train Loss: 0.0051, Time: 4.9818220138549805\n",
      "Epoch 1028/9600, Train Loss: 0.0051, Time: 4.988182306289673\n",
      "Epoch 1029/9600, Train Loss: 0.0052, Time: 4.974281549453735\n",
      "Epoch 1030/9600, Train Loss: 0.0052, Time: 4.970211744308472\n",
      "Epoch 1031/9600, Train Loss: 0.0051, Time: 4.972165584564209\n",
      "Epoch 1032/9600, Train Loss: 0.0051, Time: 4.966181755065918\n",
      "Epoch 1033/9600, Train Loss: 0.0052, Time: 4.978831052780151\n",
      "Epoch 1034/9600, Train Loss: 0.0051, Time: 4.979007005691528\n",
      "Epoch 1035/9600, Train Loss: 0.0052, Time: 4.965167284011841\n",
      "Epoch 1036/9600, Train Loss: 0.0051, Time: 4.963783502578735\n",
      "Epoch 1037/9600, Train Loss: 0.0052, Time: 4.953601360321045\n",
      "Epoch 1038/9600, Train Loss: 0.0051, Time: 4.9573423862457275\n",
      "Epoch 1039/9600, Train Loss: 0.0052, Time: 4.962176322937012\n",
      "Epoch 1040/9600, Train Loss: 0.0051, Time: 4.97482705116272\n",
      "Epoch 1041/9600, Train Loss: 0.0052, Time: 4.963231801986694\n",
      "Epoch 1042/9600, Train Loss: 0.0051, Time: 4.966308355331421\n",
      "Epoch 1043/9600, Train Loss: 0.0051, Time: 4.970799922943115\n",
      "Epoch 1044/9600, Train Loss: 0.0051, Time: 4.969563007354736\n",
      "Epoch 1045/9600, Train Loss: 0.0052, Time: 4.972211122512817\n",
      "Epoch 1046/9600, Train Loss: 0.0051, Time: 4.970056533813477\n",
      "Epoch 1047/9600, Train Loss: 0.0051, Time: 4.973822832107544\n",
      "Epoch 1048/9600, Train Loss: 0.0052, Time: 4.958598613739014\n",
      "Epoch 1049/9600, Train Loss: 0.0051, Time: 4.96010947227478\n",
      "Epoch 1050/9600, Train Loss: 0.0051, Time: 4.951899290084839\n",
      "Epoch 1051/9600, Train Loss: 0.0051, Time: 4.958855628967285\n",
      "Epoch 1052/9600, Train Loss: 0.0051, Time: 4.955542325973511\n",
      "Epoch 1053/9600, Train Loss: 0.0051, Time: 4.971367597579956\n",
      "Epoch 1054/9600, Train Loss: 0.0051, Time: 4.9666907787323\n",
      "Epoch 1055/9600, Train Loss: 0.0051, Time: 4.972980499267578\n",
      "Epoch 1056/9600, Train Loss: 0.0051, Time: 4.966281175613403\n",
      "Epoch 1057/9600, Train Loss: 0.0051, Time: 4.974061965942383\n",
      "Epoch 1058/9600, Train Loss: 0.0051, Time: 4.996989965438843\n",
      "Epoch 1059/9600, Train Loss: 0.0051, Time: 4.978153467178345\n",
      "Epoch 1060/9600, Train Loss: 0.0051, Time: 4.961204528808594\n",
      "Epoch 1061/9600, Train Loss: 0.0051, Time: 4.957387924194336\n",
      "Epoch 1062/9600, Train Loss: 0.0051, Time: 4.954496145248413\n",
      "Epoch 1063/9600, Train Loss: 0.0052, Time: 4.962215185165405\n",
      "Epoch 1064/9600, Train Loss: 0.0051, Time: 4.96984338760376\n",
      "Epoch 1065/9600, Train Loss: 0.0052, Time: 4.961405992507935\n",
      "Epoch 1066/9600, Train Loss: 0.0051, Time: 4.967161178588867\n",
      "Epoch 1067/9600, Train Loss: 0.0051, Time: 4.973070383071899\n",
      "Epoch 1068/9600, Train Loss: 0.0051, Time: 4.968522787094116\n",
      "Epoch 1069/9600, Train Loss: 0.0051, Time: 4.970191955566406\n",
      "Epoch 1070/9600, Train Loss: 0.0051, Time: 4.978481292724609\n",
      "Epoch 1071/9600, Train Loss: 0.0051, Time: 4.965520143508911\n",
      "Epoch 1072/9600, Train Loss: 0.0051, Time: 4.962702751159668\n",
      "Epoch 1073/9600, Train Loss: 0.0051, Time: 4.959648847579956\n",
      "Epoch 1074/9600, Train Loss: 0.0052, Time: 4.972905397415161\n",
      "Epoch 1075/9600, Train Loss: 0.0051, Time: 4.987424850463867\n",
      "Epoch 1076/9600, Train Loss: 0.0052, Time: 4.985147953033447\n",
      "Epoch 1077/9600, Train Loss: 0.0052, Time: 4.979771614074707\n",
      "Epoch 1078/9600, Train Loss: 0.0051, Time: 4.981090784072876\n",
      "Epoch 1079/9600, Train Loss: 0.0051, Time: 4.979682922363281\n",
      "Epoch 1080/9600, Train Loss: 0.0051, Time: 4.9810826778411865\n",
      "Epoch 1081/9600, Train Loss: 0.0052, Time: 4.9845194816589355\n",
      "Epoch 1082/9600, Train Loss: 0.0051, Time: 4.972870349884033\n",
      "Epoch 1083/9600, Train Loss: 0.0051, Time: 4.972943305969238\n",
      "Epoch 1084/9600, Train Loss: 0.0051, Time: 4.9665586948394775\n",
      "Epoch 1085/9600, Train Loss: 0.0051, Time: 4.955847263336182\n",
      "Epoch 1086/9600, Train Loss: 0.0051, Time: 4.961834669113159\n",
      "Epoch 1087/9600, Train Loss: 0.0051, Time: 4.96274471282959\n",
      "Epoch 1088/9600, Train Loss: 0.0051, Time: 4.97921895980835\n",
      "Epoch 1089/9600, Train Loss: 0.0052, Time: 4.976255655288696\n",
      "Epoch 1090/9600, Train Loss: 0.0051, Time: 4.972067594528198\n",
      "Epoch 1091/9600, Train Loss: 0.0051, Time: 4.983812093734741\n",
      "Epoch 1092/9600, Train Loss: 0.0051, Time: 4.984628915786743\n",
      "Epoch 1093/9600, Train Loss: 0.0052, Time: 4.974956274032593\n",
      "Epoch 1094/9600, Train Loss: 0.0051, Time: 4.978109121322632\n",
      "Epoch 1095/9600, Train Loss: 0.0051, Time: 4.980437994003296\n",
      "Epoch 1096/9600, Train Loss: 0.0051, Time: 4.9653167724609375\n",
      "Epoch 1097/9600, Train Loss: 0.0051, Time: 4.962734937667847\n",
      "Epoch 1098/9600, Train Loss: 0.0051, Time: 4.954235315322876\n",
      "Epoch 1099/9600, Train Loss: 0.0051, Time: 4.964969873428345\n",
      "Epoch 1100/9600, Train Loss: 0.0052, Time: 4.958179950714111\n",
      "Epoch 1101/9600, Train Loss: 0.0051, Time: 4.972737073898315\n",
      "Epoch 1102/9600, Train Loss: 0.0051, Time: 4.970061540603638\n",
      "Epoch 1103/9600, Train Loss: 0.0051, Time: 4.97883677482605\n",
      "Epoch 1104/9600, Train Loss: 0.0052, Time: 4.974955081939697\n",
      "Epoch 1105/9600, Train Loss: 0.0052, Time: 4.9774463176727295\n",
      "Epoch 1106/9600, Train Loss: 0.0051, Time: 4.988617420196533\n",
      "Epoch 1107/9600, Train Loss: 0.0051, Time: 4.965901613235474\n",
      "Epoch 1108/9600, Train Loss: 0.0051, Time: 4.972848176956177\n",
      "Epoch 1109/9600, Train Loss: 0.0052, Time: 4.96728777885437\n",
      "Epoch 1110/9600, Train Loss: 0.0051, Time: 4.969118118286133\n",
      "Epoch 1111/9600, Train Loss: 0.0051, Time: 4.960466623306274\n",
      "Epoch 1112/9600, Train Loss: 0.0052, Time: 4.971896409988403\n",
      "Epoch 1113/9600, Train Loss: 0.0051, Time: 4.956421136856079\n",
      "Epoch 1114/9600, Train Loss: 0.0051, Time: 4.9774415493011475\n",
      "Epoch 1115/9600, Train Loss: 0.0051, Time: 4.96189546585083\n",
      "Epoch 1116/9600, Train Loss: 0.0051, Time: 4.967496156692505\n",
      "Epoch 1117/9600, Train Loss: 0.0051, Time: 4.9654481410980225\n",
      "Epoch 1118/9600, Train Loss: 0.0051, Time: 4.969339609146118\n",
      "Epoch 1119/9600, Train Loss: 0.0051, Time: 4.971196174621582\n",
      "Epoch 1120/9600, Train Loss: 0.0051, Time: 4.968430280685425\n",
      "Epoch 1121/9600, Train Loss: 0.0052, Time: 4.97494101524353\n",
      "Epoch 1122/9600, Train Loss: 0.0051, Time: 4.9721033573150635\n",
      "Epoch 1123/9600, Train Loss: 0.0051, Time: 4.968066453933716\n",
      "Epoch 1124/9600, Train Loss: 0.0051, Time: 4.956082582473755\n",
      "Epoch 1125/9600, Train Loss: 0.0051, Time: 4.963140487670898\n",
      "Epoch 1126/9600, Train Loss: 0.0051, Time: 4.970277309417725\n",
      "Epoch 1127/9600, Train Loss: 0.0051, Time: 4.964884996414185\n",
      "Epoch 1128/9600, Train Loss: 0.0051, Time: 4.967633485794067\n",
      "Epoch 1129/9600, Train Loss: 0.0051, Time: 4.965762138366699\n",
      "Epoch 1130/9600, Train Loss: 0.0051, Time: 4.970966339111328\n",
      "Epoch 1131/9600, Train Loss: 0.0051, Time: 4.975961208343506\n",
      "Epoch 1132/9600, Train Loss: 0.0051, Time: 4.975887775421143\n",
      "Epoch 1133/9600, Train Loss: 0.0051, Time: 4.969296932220459\n",
      "Epoch 1134/9600, Train Loss: 0.0051, Time: 4.968813419342041\n",
      "Epoch 1135/9600, Train Loss: 0.0052, Time: 4.973377466201782\n",
      "Epoch 1136/9600, Train Loss: 0.0051, Time: 4.965405702590942\n",
      "Epoch 1137/9600, Train Loss: 0.0051, Time: 4.979799509048462\n",
      "Epoch 1138/9600, Train Loss: 0.0051, Time: 4.97835898399353\n",
      "Epoch 1139/9600, Train Loss: 0.0051, Time: 4.962350368499756\n",
      "Epoch 1140/9600, Train Loss: 0.0051, Time: 4.946548223495483\n",
      "Epoch 1141/9600, Train Loss: 0.0052, Time: 4.966023683547974\n",
      "Epoch 1142/9600, Train Loss: 0.0051, Time: 4.959694147109985\n",
      "Epoch 1143/9600, Train Loss: 0.0051, Time: 4.966071605682373\n",
      "Epoch 1144/9600, Train Loss: 0.0051, Time: 4.968050956726074\n",
      "Epoch 1145/9600, Train Loss: 0.0051, Time: 4.978139400482178\n",
      "Epoch 1146/9600, Train Loss: 0.0051, Time: 4.9751362800598145\n",
      "Epoch 1147/9600, Train Loss: 0.0051, Time: 4.969634056091309\n",
      "Epoch 1148/9600, Train Loss: 0.0051, Time: 4.992620944976807\n",
      "Epoch 1149/9600, Train Loss: 0.0051, Time: 4.985485792160034\n",
      "Epoch 1150/9600, Train Loss: 0.0051, Time: 4.983114719390869\n",
      "Epoch 1151/9600, Train Loss: 0.0051, Time: 4.983948469161987\n",
      "Epoch 1152/9600, Train Loss: 0.0051, Time: 4.964767217636108\n",
      "Epoch 1153/9600, Train Loss: 0.0051, Time: 4.976320743560791\n",
      "Epoch 1154/9600, Train Loss: 0.0051, Time: 4.9848244190216064\n",
      "Epoch 1155/9600, Train Loss: 0.0052, Time: 4.981125116348267\n",
      "Epoch 1156/9600, Train Loss: 0.0051, Time: 4.978631019592285\n",
      "Epoch 1157/9600, Train Loss: 0.0051, Time: 4.9832987785339355\n",
      "Epoch 1158/9600, Train Loss: 0.0051, Time: 4.977336168289185\n",
      "Epoch 1159/9600, Train Loss: 0.0051, Time: 4.975623846054077\n",
      "Epoch 1160/9600, Train Loss: 0.0051, Time: 4.9696948528289795\n",
      "Epoch 1161/9600, Train Loss: 0.0052, Time: 4.9822046756744385\n",
      "Epoch 1162/9600, Train Loss: 0.0051, Time: 4.97612190246582\n",
      "Epoch 1163/9600, Train Loss: 0.0051, Time: 4.972713232040405\n",
      "Epoch 1164/9600, Train Loss: 0.0051, Time: 4.984495401382446\n",
      "Epoch 1165/9600, Train Loss: 0.0051, Time: 4.979220628738403\n",
      "Epoch 1166/9600, Train Loss: 0.0051, Time: 4.980165958404541\n",
      "Epoch 1167/9600, Train Loss: 0.0051, Time: 4.982961654663086\n",
      "Epoch 1168/9600, Train Loss: 0.0051, Time: 4.977757215499878\n",
      "Epoch 1169/9600, Train Loss: 0.0051, Time: 4.971211671829224\n",
      "Epoch 1170/9600, Train Loss: 0.0051, Time: 4.96484112739563\n",
      "Epoch 1171/9600, Train Loss: 0.0051, Time: 4.9684226512908936\n",
      "Epoch 1172/9600, Train Loss: 0.0051, Time: 4.959832429885864\n",
      "Epoch 1173/9600, Train Loss: 0.0051, Time: 4.966284275054932\n",
      "Epoch 1174/9600, Train Loss: 0.0051, Time: 4.978965759277344\n",
      "Epoch 1175/9600, Train Loss: 0.0051, Time: 4.959174633026123\n",
      "Epoch 1176/9600, Train Loss: 0.0051, Time: 4.964260578155518\n",
      "Epoch 1177/9600, Train Loss: 0.0051, Time: 4.974754333496094\n",
      "Epoch 1178/9600, Train Loss: 0.0051, Time: 4.9597487449646\n",
      "Epoch 1179/9600, Train Loss: 0.0051, Time: 4.970564126968384\n",
      "Epoch 1180/9600, Train Loss: 0.0052, Time: 4.967715501785278\n",
      "Epoch 1181/9600, Train Loss: 0.0051, Time: 4.960753679275513\n",
      "Epoch 1182/9600, Train Loss: 0.0051, Time: 4.9947874546051025\n",
      "Epoch 1183/9600, Train Loss: 0.0051, Time: 4.9662766456604\n",
      "Epoch 1184/9600, Train Loss: 0.0051, Time: 4.955604314804077\n",
      "Epoch 1185/9600, Train Loss: 0.0051, Time: 4.962111949920654\n",
      "Epoch 1186/9600, Train Loss: 0.0051, Time: 4.970654726028442\n",
      "Epoch 1187/9600, Train Loss: 0.0051, Time: 4.96819806098938\n",
      "Epoch 1188/9600, Train Loss: 0.0050, Time: 4.963759660720825\n",
      "Epoch 1189/9600, Train Loss: 0.0051, Time: 4.961682319641113\n",
      "Epoch 1190/9600, Train Loss: 0.0051, Time: 4.974343299865723\n",
      "Epoch 1191/9600, Train Loss: 0.0050, Time: 4.970707893371582\n",
      "Epoch 1192/9600, Train Loss: 0.0051, Time: 4.9739179611206055\n",
      "Epoch 1193/9600, Train Loss: 0.0050, Time: 4.957711935043335\n",
      "Epoch 1194/9600, Train Loss: 0.0051, Time: 4.958148002624512\n",
      "Epoch 1195/9600, Train Loss: 0.0051, Time: 4.95075798034668\n",
      "Epoch 1196/9600, Train Loss: 0.0051, Time: 4.980963945388794\n",
      "Epoch 1197/9600, Train Loss: 0.0051, Time: 4.973718166351318\n",
      "Epoch 1198/9600, Train Loss: 0.0051, Time: 4.96851372718811\n",
      "Epoch 1199/9600, Train Loss: 0.0051, Time: 4.953183174133301\n",
      "Epoch 1200/9600, Train Loss: 0.0051, Time: 4.966521501541138\n",
      "Epoch 1201/9600, Train Loss: 0.0052, Time: 4.957356214523315\n",
      "Epoch 1202/9600, Train Loss: 0.0051, Time: 4.978806495666504\n",
      "Epoch 1203/9600, Train Loss: 0.0051, Time: 4.969898223876953\n",
      "Epoch 1204/9600, Train Loss: 0.0051, Time: 4.965039253234863\n",
      "Epoch 1205/9600, Train Loss: 0.0051, Time: 4.964240074157715\n",
      "Epoch 1206/9600, Train Loss: 0.0052, Time: 4.9690046310424805\n",
      "Epoch 1207/9600, Train Loss: 0.0051, Time: 4.970240354537964\n",
      "Epoch 1208/9600, Train Loss: 0.0050, Time: 4.957792520523071\n",
      "Epoch 1209/9600, Train Loss: 0.0051, Time: 4.967638254165649\n",
      "Epoch 1210/9600, Train Loss: 0.0051, Time: 4.969520568847656\n",
      "Epoch 1211/9600, Train Loss: 0.0052, Time: 4.940222501754761\n",
      "Epoch 1212/9600, Train Loss: 0.0052, Time: 4.961954832077026\n",
      "Epoch 1213/9600, Train Loss: 0.0052, Time: 4.972493410110474\n",
      "Epoch 1214/9600, Train Loss: 0.0051, Time: 4.955526113510132\n",
      "Epoch 1215/9600, Train Loss: 0.0051, Time: 4.95228910446167\n",
      "Epoch 1216/9600, Train Loss: 0.0051, Time: 4.967415809631348\n",
      "Epoch 1217/9600, Train Loss: 0.0051, Time: 4.961191892623901\n",
      "Epoch 1218/9600, Train Loss: 0.0050, Time: 4.963181495666504\n",
      "Epoch 1219/9600, Train Loss: 0.0051, Time: 4.95604133605957\n",
      "Epoch 1220/9600, Train Loss: 0.0050, Time: 4.959041118621826\n",
      "Epoch 1221/9600, Train Loss: 0.0051, Time: 4.964577674865723\n",
      "Epoch 1222/9600, Train Loss: 0.0051, Time: 4.972676992416382\n",
      "Epoch 1223/9600, Train Loss: 0.0051, Time: 4.9696924686431885\n",
      "Epoch 1224/9600, Train Loss: 0.0051, Time: 4.973222732543945\n",
      "Epoch 1225/9600, Train Loss: 0.0051, Time: 4.964599609375\n",
      "Epoch 1226/9600, Train Loss: 0.0051, Time: 4.968984127044678\n",
      "Epoch 1227/9600, Train Loss: 0.0051, Time: 4.970940589904785\n",
      "Epoch 1228/9600, Train Loss: 0.0051, Time: 4.971359014511108\n",
      "Epoch 1229/9600, Train Loss: 0.0051, Time: 4.976925849914551\n",
      "Epoch 1230/9600, Train Loss: 0.0051, Time: 4.968695163726807\n",
      "Epoch 1231/9600, Train Loss: 0.0051, Time: 4.95986795425415\n",
      "Epoch 1232/9600, Train Loss: 0.0051, Time: 4.9565184116363525\n",
      "Epoch 1233/9600, Train Loss: 0.0051, Time: 4.957271099090576\n",
      "Epoch 1234/9600, Train Loss: 0.0051, Time: 4.963681221008301\n",
      "Epoch 1235/9600, Train Loss: 0.0051, Time: 4.95756196975708\n",
      "Epoch 1236/9600, Train Loss: 0.0051, Time: 4.966099739074707\n",
      "Epoch 1237/9600, Train Loss: 0.0051, Time: 4.961549520492554\n",
      "Epoch 1238/9600, Train Loss: 0.0051, Time: 4.970013380050659\n",
      "Epoch 1239/9600, Train Loss: 0.0050, Time: 4.967689275741577\n",
      "Epoch 1240/9600, Train Loss: 0.0050, Time: 4.9695210456848145\n",
      "Epoch 1241/9600, Train Loss: 0.0051, Time: 4.9692442417144775\n",
      "Epoch 1242/9600, Train Loss: 0.0051, Time: 4.963530540466309\n",
      "Epoch 1243/9600, Train Loss: 0.0051, Time: 4.96419095993042\n",
      "Epoch 1244/9600, Train Loss: 0.0051, Time: 4.97034764289856\n",
      "Epoch 1245/9600, Train Loss: 0.0051, Time: 4.960089683532715\n",
      "Epoch 1246/9600, Train Loss: 0.0050, Time: 4.973817348480225\n",
      "Epoch 1247/9600, Train Loss: 0.0051, Time: 4.957977056503296\n",
      "Epoch 1248/9600, Train Loss: 0.0051, Time: 4.958756923675537\n",
      "Epoch 1249/9600, Train Loss: 0.0051, Time: 4.9537436962127686\n",
      "Epoch 1250/9600, Train Loss: 0.0050, Time: 4.964106798171997\n",
      "Epoch 1251/9600, Train Loss: 0.0051, Time: 4.964152574539185\n",
      "Epoch 1252/9600, Train Loss: 0.0051, Time: 4.954542398452759\n",
      "Epoch 1253/9600, Train Loss: 0.0051, Time: 4.951916694641113\n",
      "Epoch 1254/9600, Train Loss: 0.0051, Time: 4.967570066452026\n",
      "Epoch 1255/9600, Train Loss: 0.0051, Time: 4.961642742156982\n",
      "Epoch 1256/9600, Train Loss: 0.0051, Time: 4.9843528270721436\n",
      "Epoch 1257/9600, Train Loss: 0.0051, Time: 4.9806294441223145\n",
      "Epoch 1258/9600, Train Loss: 0.0052, Time: 4.9689249992370605\n",
      "Epoch 1259/9600, Train Loss: 0.0051, Time: 4.973408460617065\n",
      "Epoch 1260/9600, Train Loss: 0.0051, Time: 4.974442481994629\n",
      "Epoch 1261/9600, Train Loss: 0.0051, Time: 4.963707685470581\n",
      "Epoch 1262/9600, Train Loss: 0.0050, Time: 4.978601694107056\n",
      "Epoch 1263/9600, Train Loss: 0.0051, Time: 4.976187229156494\n",
      "Epoch 1264/9600, Train Loss: 0.0051, Time: 4.9666924476623535\n",
      "Epoch 1265/9600, Train Loss: 0.0051, Time: 4.968889951705933\n",
      "Epoch 1266/9600, Train Loss: 0.0051, Time: 4.960129022598267\n",
      "Epoch 1267/9600, Train Loss: 0.0051, Time: 4.962468862533569\n",
      "Epoch 1268/9600, Train Loss: 0.0051, Time: 4.960982084274292\n",
      "Epoch 1269/9600, Train Loss: 0.0051, Time: 4.955191612243652\n",
      "Epoch 1270/9600, Train Loss: 0.0051, Time: 4.96762752532959\n",
      "Epoch 1271/9600, Train Loss: 0.0051, Time: 4.9725096225738525\n",
      "Epoch 1272/9600, Train Loss: 0.0051, Time: 4.9737772941589355\n",
      "Epoch 1273/9600, Train Loss: 0.0051, Time: 4.960919141769409\n",
      "Epoch 1274/9600, Train Loss: 0.0051, Time: 4.967808246612549\n",
      "Epoch 1275/9600, Train Loss: 0.0051, Time: 4.97889518737793\n",
      "Epoch 1276/9600, Train Loss: 0.0050, Time: 4.9690587520599365\n",
      "Epoch 1277/9600, Train Loss: 0.0051, Time: 4.976160287857056\n",
      "Epoch 1278/9600, Train Loss: 0.0050, Time: 4.973379135131836\n",
      "Epoch 1279/9600, Train Loss: 0.0051, Time: 4.9610724449157715\n",
      "Epoch 1280/9600, Train Loss: 0.0051, Time: 4.975862264633179\n",
      "Epoch 1281/9600, Train Loss: 0.0051, Time: 4.966837167739868\n",
      "Epoch 1282/9600, Train Loss: 0.0051, Time: 4.9712748527526855\n",
      "Epoch 1283/9600, Train Loss: 0.0051, Time: 4.975146770477295\n",
      "Epoch 1284/9600, Train Loss: 0.0051, Time: 4.962393283843994\n",
      "Epoch 1285/9600, Train Loss: 0.0051, Time: 4.960909128189087\n",
      "Epoch 1286/9600, Train Loss: 0.0051, Time: 4.972803592681885\n",
      "Epoch 1287/9600, Train Loss: 0.0051, Time: 4.976978302001953\n",
      "Epoch 1288/9600, Train Loss: 0.0051, Time: 4.9723052978515625\n",
      "Epoch 1289/9600, Train Loss: 0.0051, Time: 4.976304769515991\n",
      "Epoch 1290/9600, Train Loss: 0.0051, Time: 4.981199741363525\n",
      "Epoch 1291/9600, Train Loss: 0.0051, Time: 4.9743475914001465\n",
      "Epoch 1292/9600, Train Loss: 0.0052, Time: 4.962570905685425\n",
      "Epoch 1293/9600, Train Loss: 0.0051, Time: 4.960231065750122\n",
      "Epoch 1294/9600, Train Loss: 0.0051, Time: 4.968699216842651\n",
      "Epoch 1295/9600, Train Loss: 0.0051, Time: 4.980439901351929\n",
      "Epoch 1296/9600, Train Loss: 0.0051, Time: 4.962573289871216\n",
      "Epoch 1297/9600, Train Loss: 0.0051, Time: 4.958354234695435\n",
      "Epoch 1298/9600, Train Loss: 0.0051, Time: 4.95554256439209\n",
      "Epoch 1299/9600, Train Loss: 0.0051, Time: 4.961376428604126\n",
      "Epoch 1300/9600, Train Loss: 0.0051, Time: 4.96320104598999\n",
      "Epoch 1301/9600, Train Loss: 0.0051, Time: 4.962447643280029\n",
      "Epoch 1302/9600, Train Loss: 0.0051, Time: 4.973188877105713\n",
      "Epoch 1303/9600, Train Loss: 0.0052, Time: 4.967327117919922\n",
      "Epoch 1304/9600, Train Loss: 0.0051, Time: 4.958303928375244\n",
      "Epoch 1305/9600, Train Loss: 0.0051, Time: 4.964257717132568\n",
      "Epoch 1306/9600, Train Loss: 0.0051, Time: 4.975306987762451\n",
      "Epoch 1307/9600, Train Loss: 0.0051, Time: 4.971412420272827\n",
      "Epoch 1308/9600, Train Loss: 0.0052, Time: 4.975932598114014\n",
      "Epoch 1309/9600, Train Loss: 0.0051, Time: 4.964449167251587\n",
      "Epoch 1310/9600, Train Loss: 0.0051, Time: 4.97267746925354\n",
      "Epoch 1311/9600, Train Loss: 0.0050, Time: 4.966955900192261\n",
      "Epoch 1312/9600, Train Loss: 0.0051, Time: 4.961523056030273\n",
      "Epoch 1313/9600, Train Loss: 0.0051, Time: 4.965498685836792\n",
      "Epoch 1314/9600, Train Loss: 0.0051, Time: 4.971658706665039\n",
      "Epoch 1315/9600, Train Loss: 0.0051, Time: 4.965489864349365\n",
      "Epoch 1316/9600, Train Loss: 0.0051, Time: 4.973734378814697\n",
      "Epoch 1317/9600, Train Loss: 0.0051, Time: 4.9752516746521\n",
      "Epoch 1318/9600, Train Loss: 0.0051, Time: 4.980917453765869\n",
      "Epoch 1319/9600, Train Loss: 0.0051, Time: 4.9670305252075195\n",
      "Epoch 1320/9600, Train Loss: 0.0050, Time: 4.967141389846802\n",
      "Epoch 1321/9600, Train Loss: 0.0052, Time: 4.960864305496216\n",
      "Epoch 1322/9600, Train Loss: 0.0051, Time: 4.966514587402344\n",
      "Epoch 1323/9600, Train Loss: 0.0051, Time: 4.961924076080322\n",
      "Epoch 1324/9600, Train Loss: 0.0051, Time: 4.97381329536438\n",
      "Epoch 1325/9600, Train Loss: 0.0051, Time: 4.964795351028442\n",
      "Epoch 1326/9600, Train Loss: 0.0051, Time: 4.975571870803833\n",
      "Epoch 1327/9600, Train Loss: 0.0051, Time: 4.967399597167969\n",
      "Epoch 1328/9600, Train Loss: 0.0051, Time: 4.973198652267456\n",
      "Epoch 1329/9600, Train Loss: 0.0051, Time: 4.9738311767578125\n",
      "Epoch 1330/9600, Train Loss: 0.0051, Time: 4.967529535293579\n",
      "Epoch 1331/9600, Train Loss: 0.0051, Time: 4.973536968231201\n",
      "Epoch 1332/9600, Train Loss: 0.0051, Time: 4.968048095703125\n",
      "Epoch 1333/9600, Train Loss: 0.0051, Time: 4.969998598098755\n",
      "Epoch 1334/9600, Train Loss: 0.0052, Time: 4.976244688034058\n",
      "Epoch 1335/9600, Train Loss: 0.0050, Time: 4.96355676651001\n",
      "Epoch 1336/9600, Train Loss: 0.0051, Time: 4.98185133934021\n",
      "Epoch 1337/9600, Train Loss: 0.0050, Time: 4.981895923614502\n",
      "Epoch 1338/9600, Train Loss: 0.0051, Time: 4.956554651260376\n",
      "Epoch 1339/9600, Train Loss: 0.0050, Time: 4.952528476715088\n",
      "Epoch 1340/9600, Train Loss: 0.0051, Time: 4.964287757873535\n",
      "Epoch 1341/9600, Train Loss: 0.0051, Time: 4.962325811386108\n",
      "Epoch 1342/9600, Train Loss: 0.0051, Time: 4.960144996643066\n",
      "Epoch 1343/9600, Train Loss: 0.0050, Time: 4.967517614364624\n",
      "Epoch 1344/9600, Train Loss: 0.0051, Time: 4.9590065479278564\n",
      "Epoch 1345/9600, Train Loss: 0.0051, Time: 4.963060617446899\n",
      "Epoch 1346/9600, Train Loss: 0.0051, Time: 4.956345558166504\n",
      "Epoch 1347/9600, Train Loss: 0.0052, Time: 4.968985080718994\n",
      "Epoch 1348/9600, Train Loss: 0.0051, Time: 4.970904350280762\n",
      "Epoch 1349/9600, Train Loss: 0.0051, Time: 4.9683518409729\n",
      "Epoch 1350/9600, Train Loss: 0.0051, Time: 4.968289375305176\n",
      "Epoch 1351/9600, Train Loss: 0.0051, Time: 4.975219964981079\n",
      "Epoch 1352/9600, Train Loss: 0.0051, Time: 4.967884302139282\n",
      "Epoch 1353/9600, Train Loss: 0.0051, Time: 4.959451913833618\n",
      "Epoch 1354/9600, Train Loss: 0.0050, Time: 4.962110757827759\n",
      "Epoch 1355/9600, Train Loss: 0.0050, Time: 4.965518236160278\n",
      "Epoch 1356/9600, Train Loss: 0.0050, Time: 4.951329469680786\n",
      "Epoch 1357/9600, Train Loss: 0.0051, Time: 4.960446119308472\n",
      "Epoch 1358/9600, Train Loss: 0.0050, Time: 4.967435598373413\n",
      "Epoch 1359/9600, Train Loss: 0.0051, Time: 4.979112386703491\n",
      "Epoch 1360/9600, Train Loss: 0.0051, Time: 4.974518775939941\n",
      "Epoch 1361/9600, Train Loss: 0.0051, Time: 4.9759814739227295\n",
      "Epoch 1362/9600, Train Loss: 0.0050, Time: 4.973960876464844\n",
      "Epoch 1363/9600, Train Loss: 0.0052, Time: 4.972008228302002\n",
      "Epoch 1364/9600, Train Loss: 0.0050, Time: 4.965211868286133\n",
      "Epoch 1365/9600, Train Loss: 0.0051, Time: 4.983668327331543\n",
      "Epoch 1366/9600, Train Loss: 0.0051, Time: 4.97275447845459\n",
      "Epoch 1367/9600, Train Loss: 0.0051, Time: 4.958934545516968\n",
      "Epoch 1368/9600, Train Loss: 0.0051, Time: 4.966642379760742\n",
      "Epoch 1369/9600, Train Loss: 0.0050, Time: 4.958060264587402\n",
      "Epoch 1370/9600, Train Loss: 0.0051, Time: 4.956626892089844\n",
      "Epoch 1371/9600, Train Loss: 0.0050, Time: 4.96448016166687\n",
      "Epoch 1372/9600, Train Loss: 0.0051, Time: 4.9700539112091064\n",
      "Epoch 1373/9600, Train Loss: 0.0051, Time: 4.971637964248657\n",
      "Epoch 1374/9600, Train Loss: 0.0051, Time: 4.969454050064087\n",
      "Epoch 1375/9600, Train Loss: 0.0051, Time: 4.97391414642334\n",
      "Epoch 1376/9600, Train Loss: 0.0050, Time: 4.973891735076904\n",
      "Epoch 1377/9600, Train Loss: 0.0051, Time: 4.96575665473938\n",
      "Epoch 1378/9600, Train Loss: 0.0051, Time: 4.973016023635864\n",
      "Epoch 1379/9600, Train Loss: 0.0051, Time: 4.973833322525024\n",
      "Epoch 1380/9600, Train Loss: 0.0051, Time: 4.963978052139282\n",
      "Epoch 1381/9600, Train Loss: 0.0051, Time: 4.96329140663147\n",
      "Epoch 1382/9600, Train Loss: 0.0051, Time: 4.96561861038208\n",
      "Epoch 1383/9600, Train Loss: 0.0051, Time: 4.96940016746521\n",
      "Epoch 1384/9600, Train Loss: 0.0051, Time: 4.966949224472046\n",
      "Epoch 1385/9600, Train Loss: 0.0051, Time: 4.970126390457153\n",
      "Epoch 1386/9600, Train Loss: 0.0050, Time: 4.968817234039307\n",
      "Epoch 1387/9600, Train Loss: 0.0052, Time: 4.977487087249756\n",
      "Epoch 1388/9600, Train Loss: 0.0050, Time: 4.98000168800354\n",
      "Epoch 1389/9600, Train Loss: 0.0051, Time: 4.973940372467041\n",
      "Epoch 1390/9600, Train Loss: 0.0051, Time: 4.964064121246338\n",
      "Epoch 1391/9600, Train Loss: 0.0050, Time: 4.977867841720581\n",
      "Epoch 1392/9600, Train Loss: 0.0051, Time: 4.975184917449951\n",
      "Epoch 1393/9600, Train Loss: 0.0051, Time: 4.980292081832886\n",
      "Epoch 1394/9600, Train Loss: 0.0051, Time: 4.971412658691406\n",
      "Epoch 1395/9600, Train Loss: 0.0050, Time: 4.976043701171875\n",
      "Epoch 1396/9600, Train Loss: 0.0050, Time: 4.971778154373169\n",
      "Epoch 1397/9600, Train Loss: 0.0051, Time: 4.968658447265625\n",
      "Epoch 1398/9600, Train Loss: 0.0051, Time: 4.96447491645813\n",
      "Epoch 1399/9600, Train Loss: 0.0051, Time: 4.964928388595581\n",
      "Epoch 1400/9600, Train Loss: 0.0050, Time: 4.959585189819336\n",
      "Epoch 1401/9600, Train Loss: 0.0050, Time: 4.966721296310425\n",
      "Epoch 1402/9600, Train Loss: 0.0051, Time: 4.969395637512207\n",
      "Epoch 1403/9600, Train Loss: 0.0051, Time: 4.972329139709473\n",
      "Epoch 1404/9600, Train Loss: 0.0051, Time: 4.967166900634766\n",
      "Epoch 1405/9600, Train Loss: 0.0051, Time: 4.972839117050171\n",
      "Epoch 1406/9600, Train Loss: 0.0051, Time: 4.9684083461761475\n",
      "Epoch 1407/9600, Train Loss: 0.0050, Time: 4.9704835414886475\n",
      "Epoch 1408/9600, Train Loss: 0.0051, Time: 4.975071668624878\n",
      "Epoch 1409/9600, Train Loss: 0.0050, Time: 4.960839748382568\n",
      "Epoch 1410/9600, Train Loss: 0.0051, Time: 4.977220058441162\n",
      "Epoch 1411/9600, Train Loss: 0.0051, Time: 4.967097997665405\n",
      "Epoch 1412/9600, Train Loss: 0.0051, Time: 4.953760623931885\n",
      "Epoch 1413/9600, Train Loss: 0.0051, Time: 4.965469598770142\n",
      "Epoch 1414/9600, Train Loss: 0.0051, Time: 4.965454578399658\n",
      "Epoch 1415/9600, Train Loss: 0.0051, Time: 4.962173223495483\n",
      "Epoch 1416/9600, Train Loss: 0.0051, Time: 4.967003583908081\n",
      "Epoch 1417/9600, Train Loss: 0.0051, Time: 4.96683144569397\n",
      "Epoch 1418/9600, Train Loss: 0.0050, Time: 4.971575021743774\n",
      "Epoch 1419/9600, Train Loss: 0.0051, Time: 4.9561381340026855\n",
      "Epoch 1420/9600, Train Loss: 0.0051, Time: 4.9628355503082275\n",
      "Epoch 1421/9600, Train Loss: 0.0050, Time: 4.957298755645752\n",
      "Epoch 1422/9600, Train Loss: 0.0051, Time: 4.965921401977539\n",
      "Epoch 1423/9600, Train Loss: 0.0050, Time: 4.958747148513794\n",
      "Epoch 1424/9600, Train Loss: 0.0051, Time: 4.955870151519775\n",
      "Epoch 1425/9600, Train Loss: 0.0051, Time: 4.952836513519287\n",
      "Epoch 1426/9600, Train Loss: 0.0051, Time: 4.959572076797485\n",
      "Epoch 1427/9600, Train Loss: 0.0052, Time: 4.960157632827759\n",
      "Epoch 1428/9600, Train Loss: 0.0051, Time: 4.967928647994995\n",
      "Epoch 1429/9600, Train Loss: 0.0050, Time: 4.96671462059021\n",
      "Epoch 1430/9600, Train Loss: 0.0050, Time: 4.95871901512146\n",
      "Epoch 1431/9600, Train Loss: 0.0051, Time: 4.973417282104492\n",
      "Epoch 1432/9600, Train Loss: 0.0050, Time: 4.969900131225586\n",
      "Epoch 1433/9600, Train Loss: 0.0051, Time: 4.963668346405029\n",
      "Epoch 1434/9600, Train Loss: 0.0051, Time: 4.95958399772644\n",
      "Epoch 1435/9600, Train Loss: 0.0051, Time: 4.968554496765137\n",
      "Epoch 1436/9600, Train Loss: 0.0051, Time: 4.966678142547607\n",
      "Epoch 1437/9600, Train Loss: 0.0050, Time: 4.972079038619995\n",
      "Epoch 1438/9600, Train Loss: 0.0051, Time: 4.984376907348633\n",
      "Epoch 1439/9600, Train Loss: 0.0051, Time: 4.966357707977295\n",
      "Epoch 1440/9600, Train Loss: 0.0051, Time: 4.979587078094482\n",
      "Epoch 1441/9600, Train Loss: 0.0050, Time: 4.967573642730713\n",
      "Epoch 1442/9600, Train Loss: 0.0051, Time: 4.968241214752197\n",
      "Epoch 1443/9600, Train Loss: 0.0050, Time: 4.954390048980713\n",
      "Epoch 1444/9600, Train Loss: 0.0051, Time: 4.965663433074951\n",
      "Epoch 1445/9600, Train Loss: 0.0051, Time: 4.964538335800171\n",
      "Epoch 1446/9600, Train Loss: 0.0051, Time: 4.963228940963745\n",
      "Epoch 1447/9600, Train Loss: 0.0051, Time: 4.972692012786865\n",
      "Epoch 1448/9600, Train Loss: 0.0051, Time: 4.964987516403198\n",
      "Epoch 1449/9600, Train Loss: 0.0051, Time: 4.958317756652832\n",
      "Epoch 1450/9600, Train Loss: 0.0051, Time: 4.954598903656006\n",
      "Epoch 1451/9600, Train Loss: 0.0050, Time: 4.961336135864258\n",
      "Epoch 1452/9600, Train Loss: 0.0051, Time: 4.957837343215942\n",
      "Epoch 1453/9600, Train Loss: 0.0051, Time: 4.959096431732178\n",
      "Epoch 1454/9600, Train Loss: 0.0050, Time: 4.954592227935791\n",
      "Epoch 1455/9600, Train Loss: 0.0051, Time: 4.964481592178345\n",
      "Epoch 1456/9600, Train Loss: 0.0050, Time: 4.96967887878418\n",
      "Epoch 1457/9600, Train Loss: 0.0051, Time: 4.964517116546631\n",
      "Epoch 1458/9600, Train Loss: 0.0051, Time: 4.970916748046875\n",
      "Epoch 1459/9600, Train Loss: 0.0050, Time: 4.970030307769775\n",
      "Epoch 1460/9600, Train Loss: 0.0050, Time: 4.971991777420044\n",
      "Epoch 1461/9600, Train Loss: 0.0051, Time: 4.9669108390808105\n",
      "Epoch 1462/9600, Train Loss: 0.0051, Time: 4.969588041305542\n",
      "Epoch 1463/9600, Train Loss: 0.0051, Time: 4.97055983543396\n",
      "Epoch 1464/9600, Train Loss: 0.0050, Time: 4.966645002365112\n",
      "Epoch 1465/9600, Train Loss: 0.0051, Time: 4.95615816116333\n",
      "Epoch 1466/9600, Train Loss: 0.0051, Time: 4.959272384643555\n",
      "Epoch 1467/9600, Train Loss: 0.0051, Time: 4.951398611068726\n",
      "Epoch 1468/9600, Train Loss: 0.0051, Time: 4.966487169265747\n",
      "Epoch 1469/9600, Train Loss: 0.0051, Time: 4.96767520904541\n",
      "Epoch 1470/9600, Train Loss: 0.0051, Time: 4.976897239685059\n",
      "Epoch 1471/9600, Train Loss: 0.0050, Time: 4.964693784713745\n",
      "Epoch 1472/9600, Train Loss: 0.0051, Time: 4.9619081020355225\n",
      "Epoch 1473/9600, Train Loss: 0.0050, Time: 4.968247175216675\n",
      "Epoch 1474/9600, Train Loss: 0.0051, Time: 4.965482711791992\n",
      "Epoch 1475/9600, Train Loss: 0.0050, Time: 4.964054822921753\n",
      "Epoch 1476/9600, Train Loss: 0.0051, Time: 4.950297594070435\n",
      "Epoch 1477/9600, Train Loss: 0.0050, Time: 4.958065748214722\n",
      "Epoch 1478/9600, Train Loss: 0.0051, Time: 4.975437641143799\n",
      "Epoch 1479/9600, Train Loss: 0.0050, Time: 4.96413516998291\n",
      "Epoch 1480/9600, Train Loss: 0.0051, Time: 4.9649083614349365\n",
      "Epoch 1481/9600, Train Loss: 0.0050, Time: 5.025563716888428\n",
      "Epoch 1482/9600, Train Loss: 0.0051, Time: 4.984760046005249\n",
      "Epoch 1483/9600, Train Loss: 0.0051, Time: 4.970619201660156\n",
      "Epoch 1484/9600, Train Loss: 0.0051, Time: 4.962786674499512\n",
      "Epoch 1485/9600, Train Loss: 0.0051, Time: 4.9648661613464355\n",
      "Epoch 1486/9600, Train Loss: 0.0051, Time: 4.962523937225342\n",
      "Epoch 1487/9600, Train Loss: 0.0051, Time: 4.967992544174194\n",
      "Epoch 1488/9600, Train Loss: 0.0050, Time: 4.961620807647705\n",
      "Epoch 1489/9600, Train Loss: 0.0051, Time: 4.95600438117981\n",
      "Epoch 1490/9600, Train Loss: 0.0050, Time: 4.958333253860474\n",
      "Epoch 1491/9600, Train Loss: 0.0051, Time: 4.961639642715454\n",
      "Epoch 1492/9600, Train Loss: 0.0050, Time: 4.962568283081055\n",
      "Epoch 1493/9600, Train Loss: 0.0051, Time: 4.971565008163452\n",
      "Epoch 1494/9600, Train Loss: 0.0051, Time: 4.961115598678589\n",
      "Epoch 1495/9600, Train Loss: 0.0050, Time: 4.9588282108306885\n",
      "Epoch 1496/9600, Train Loss: 0.0051, Time: 4.966517448425293\n",
      "Epoch 1497/9600, Train Loss: 0.0051, Time: 4.969305038452148\n",
      "Epoch 1498/9600, Train Loss: 0.0050, Time: 4.96843409538269\n",
      "Epoch 1499/9600, Train Loss: 0.0051, Time: 4.969239950180054\n",
      "Epoch 1500/9600, Train Loss: 0.0050, Time: 4.9634528160095215\n",
      "Epoch 1501/9600, Train Loss: 0.0051, Time: 4.956834077835083\n",
      "Epoch 1502/9600, Train Loss: 0.0051, Time: 4.9631428718566895\n",
      "Epoch 1503/9600, Train Loss: 0.0051, Time: 4.967538595199585\n",
      "Epoch 1504/9600, Train Loss: 0.0051, Time: 4.9740636348724365\n",
      "Epoch 1505/9600, Train Loss: 0.0051, Time: 4.9746644496917725\n",
      "Epoch 1506/9600, Train Loss: 0.0051, Time: 4.967513561248779\n",
      "Epoch 1507/9600, Train Loss: 0.0050, Time: 4.967024803161621\n",
      "Epoch 1508/9600, Train Loss: 0.0050, Time: 4.961180210113525\n",
      "Epoch 1509/9600, Train Loss: 0.0051, Time: 4.969252824783325\n",
      "Epoch 1510/9600, Train Loss: 0.0051, Time: 4.962264060974121\n",
      "Epoch 1511/9600, Train Loss: 0.0051, Time: 4.962623834609985\n",
      "Epoch 1512/9600, Train Loss: 0.0051, Time: 4.96469259262085\n",
      "Epoch 1513/9600, Train Loss: 0.0051, Time: 4.96916937828064\n",
      "Epoch 1514/9600, Train Loss: 0.0051, Time: 4.9656822681427\n",
      "Epoch 1515/9600, Train Loss: 0.0050, Time: 4.972049713134766\n",
      "Epoch 1516/9600, Train Loss: 0.0051, Time: 4.960245132446289\n",
      "Epoch 1517/9600, Train Loss: 0.0051, Time: 4.971714496612549\n",
      "Epoch 1518/9600, Train Loss: 0.0051, Time: 4.978201150894165\n",
      "Epoch 1519/9600, Train Loss: 0.0051, Time: 4.97209358215332\n",
      "Epoch 1520/9600, Train Loss: 0.0050, Time: 4.973265886306763\n",
      "Epoch 1521/9600, Train Loss: 0.0050, Time: 4.964103937149048\n",
      "Epoch 1522/9600, Train Loss: 0.0051, Time: 4.964542865753174\n",
      "Epoch 1523/9600, Train Loss: 0.0050, Time: 4.966197729110718\n",
      "Epoch 1524/9600, Train Loss: 0.0051, Time: 4.968343734741211\n",
      "Epoch 1525/9600, Train Loss: 0.0051, Time: 4.960342645645142\n",
      "Epoch 1526/9600, Train Loss: 0.0050, Time: 4.959367752075195\n",
      "Epoch 1527/9600, Train Loss: 0.0050, Time: 4.961796522140503\n",
      "Epoch 1528/9600, Train Loss: 0.0050, Time: 4.964455842971802\n",
      "Epoch 1529/9600, Train Loss: 0.0051, Time: 4.974597930908203\n",
      "Epoch 1530/9600, Train Loss: 0.0051, Time: 4.963515043258667\n",
      "Epoch 1531/9600, Train Loss: 0.0051, Time: 4.962157487869263\n",
      "Epoch 1532/9600, Train Loss: 0.0051, Time: 4.969983816146851\n",
      "Epoch 1533/9600, Train Loss: 0.0051, Time: 4.965609788894653\n",
      "Epoch 1534/9600, Train Loss: 0.0050, Time: 4.96388840675354\n",
      "Epoch 1535/9600, Train Loss: 0.0051, Time: 4.969203472137451\n",
      "Epoch 1536/9600, Train Loss: 0.0051, Time: 4.967400074005127\n",
      "Epoch 1537/9600, Train Loss: 0.0051, Time: 4.9625632762908936\n",
      "Epoch 1538/9600, Train Loss: 0.0051, Time: 4.96665096282959\n",
      "Epoch 1539/9600, Train Loss: 0.0051, Time: 4.95500373840332\n",
      "Epoch 1540/9600, Train Loss: 0.0050, Time: 4.962026119232178\n",
      "Epoch 1541/9600, Train Loss: 0.0050, Time: 4.967677354812622\n",
      "Epoch 1542/9600, Train Loss: 0.0050, Time: 4.973510980606079\n",
      "Epoch 1543/9600, Train Loss: 0.0051, Time: 4.965965747833252\n",
      "Epoch 1544/9600, Train Loss: 0.0051, Time: 4.9637486934661865\n",
      "Epoch 1545/9600, Train Loss: 0.0051, Time: 4.962109088897705\n",
      "Epoch 1546/9600, Train Loss: 0.0051, Time: 4.970282316207886\n",
      "Epoch 1547/9600, Train Loss: 0.0050, Time: 4.960731506347656\n",
      "Epoch 1548/9600, Train Loss: 0.0050, Time: 4.967848062515259\n",
      "Epoch 1549/9600, Train Loss: 0.0050, Time: 4.963515281677246\n",
      "Epoch 1550/9600, Train Loss: 0.0050, Time: 4.957951784133911\n",
      "Epoch 1551/9600, Train Loss: 0.0050, Time: 4.962337970733643\n",
      "Epoch 1552/9600, Train Loss: 0.0050, Time: 4.9632110595703125\n",
      "Epoch 1553/9600, Train Loss: 0.0051, Time: 4.965694427490234\n",
      "Epoch 1554/9600, Train Loss: 0.0050, Time: 4.966562509536743\n",
      "Epoch 1555/9600, Train Loss: 0.0051, Time: 4.960717678070068\n",
      "Epoch 1556/9600, Train Loss: 0.0051, Time: 4.9694390296936035\n",
      "Epoch 1557/9600, Train Loss: 0.0050, Time: 4.960999250411987\n",
      "Epoch 1558/9600, Train Loss: 0.0051, Time: 4.9610772132873535\n",
      "Epoch 1559/9600, Train Loss: 0.0051, Time: 4.963401556015015\n",
      "Epoch 1560/9600, Train Loss: 0.0050, Time: 4.960273027420044\n",
      "Epoch 1561/9600, Train Loss: 0.0050, Time: 4.954434633255005\n",
      "Epoch 1562/9600, Train Loss: 0.0050, Time: 4.9680891036987305\n",
      "Epoch 1563/9600, Train Loss: 0.0051, Time: 4.960943698883057\n",
      "Epoch 1564/9600, Train Loss: 0.0050, Time: 4.962312936782837\n",
      "Epoch 1565/9600, Train Loss: 0.0051, Time: 4.964775562286377\n",
      "Epoch 1566/9600, Train Loss: 0.0050, Time: 4.968603849411011\n",
      "Epoch 1567/9600, Train Loss: 0.0050, Time: 4.966841220855713\n",
      "Epoch 1568/9600, Train Loss: 0.0050, Time: 4.957916975021362\n",
      "Epoch 1569/9600, Train Loss: 0.0050, Time: 4.9618706703186035\n",
      "Epoch 1570/9600, Train Loss: 0.0051, Time: 4.967109203338623\n",
      "Epoch 1571/9600, Train Loss: 0.0050, Time: 4.969247817993164\n",
      "Epoch 1572/9600, Train Loss: 0.0051, Time: 4.970141887664795\n",
      "Epoch 1573/9600, Train Loss: 0.0051, Time: 4.975795269012451\n",
      "Epoch 1574/9600, Train Loss: 0.0051, Time: 4.96720814704895\n",
      "Epoch 1575/9600, Train Loss: 0.0051, Time: 4.971338272094727\n",
      "Epoch 1576/9600, Train Loss: 0.0051, Time: 4.980689287185669\n",
      "Epoch 1577/9600, Train Loss: 0.0051, Time: 4.965189218521118\n",
      "Epoch 1578/9600, Train Loss: 0.0051, Time: 4.973127365112305\n",
      "Epoch 1579/9600, Train Loss: 0.0051, Time: 4.975988864898682\n",
      "Epoch 1580/9600, Train Loss: 0.0050, Time: 4.9650678634643555\n",
      "Epoch 1581/9600, Train Loss: 0.0050, Time: 4.955674409866333\n",
      "Epoch 1582/9600, Train Loss: 0.0050, Time: 4.957461833953857\n",
      "Epoch 1583/9600, Train Loss: 0.0051, Time: 4.956061601638794\n",
      "Epoch 1584/9600, Train Loss: 0.0051, Time: 4.966063022613525\n",
      "Epoch 1585/9600, Train Loss: 0.0051, Time: 4.958375930786133\n",
      "Epoch 1586/9600, Train Loss: 0.0050, Time: 4.98235821723938\n",
      "Epoch 1587/9600, Train Loss: 0.0051, Time: 4.966882705688477\n",
      "Epoch 1588/9600, Train Loss: 0.0051, Time: 4.9726402759552\n",
      "Epoch 1589/9600, Train Loss: 0.0051, Time: 4.970718860626221\n",
      "Epoch 1590/9600, Train Loss: 0.0050, Time: 4.97601842880249\n",
      "Epoch 1591/9600, Train Loss: 0.0050, Time: 4.964252948760986\n",
      "Epoch 1592/9600, Train Loss: 0.0051, Time: 4.97422194480896\n",
      "Epoch 1593/9600, Train Loss: 0.0051, Time: 4.9713294506073\n",
      "Epoch 1594/9600, Train Loss: 0.0051, Time: 4.953659772872925\n",
      "Epoch 1595/9600, Train Loss: 0.0051, Time: 4.965436220169067\n",
      "Epoch 1596/9600, Train Loss: 0.0051, Time: 4.970032215118408\n",
      "Epoch 1597/9600, Train Loss: 0.0050, Time: 4.955171585083008\n",
      "Epoch 1598/9600, Train Loss: 0.0050, Time: 4.965182781219482\n",
      "Epoch 1599/9600, Train Loss: 0.0051, Time: 4.9540252685546875\n",
      "Epoch 1600/9600, Train Loss: 0.0050, Time: 4.956965923309326\n",
      "Epoch 1601/9600, Train Loss: 0.0051, Time: 4.962209463119507\n",
      "Epoch 1602/9600, Train Loss: 0.0051, Time: 4.963043451309204\n",
      "Epoch 1603/9600, Train Loss: 0.0051, Time: 4.971765756607056\n",
      "Epoch 1604/9600, Train Loss: 0.0050, Time: 4.969851732254028\n",
      "Epoch 1605/9600, Train Loss: 0.0051, Time: 4.981536865234375\n",
      "Epoch 1606/9600, Train Loss: 0.0050, Time: 4.980380296707153\n",
      "Epoch 1607/9600, Train Loss: 0.0050, Time: 4.984184503555298\n",
      "Epoch 1608/9600, Train Loss: 0.0051, Time: 4.980020046234131\n",
      "Epoch 1609/9600, Train Loss: 0.0050, Time: 4.968646764755249\n",
      "Epoch 1610/9600, Train Loss: 0.0050, Time: 4.974128484725952\n",
      "Epoch 1611/9600, Train Loss: 0.0050, Time: 4.982760429382324\n",
      "Epoch 1612/9600, Train Loss: 0.0050, Time: 4.972184658050537\n",
      "Epoch 1613/9600, Train Loss: 0.0051, Time: 4.981081962585449\n",
      "Epoch 1614/9600, Train Loss: 0.0051, Time: 4.979605197906494\n",
      "Epoch 1615/9600, Train Loss: 0.0051, Time: 4.9619317054748535\n",
      "Epoch 1616/9600, Train Loss: 0.0050, Time: 4.968369483947754\n",
      "Epoch 1617/9600, Train Loss: 0.0050, Time: 4.9753618240356445\n",
      "Epoch 1618/9600, Train Loss: 0.0050, Time: 4.959538221359253\n",
      "Epoch 1619/9600, Train Loss: 0.0050, Time: 4.969727039337158\n",
      "Epoch 1620/9600, Train Loss: 0.0051, Time: 4.970550775527954\n",
      "Epoch 1621/9600, Train Loss: 0.0050, Time: 4.9675352573394775\n",
      "Epoch 1622/9600, Train Loss: 0.0051, Time: 4.98608660697937\n",
      "Epoch 1623/9600, Train Loss: 0.0050, Time: 4.978403091430664\n",
      "Epoch 1624/9600, Train Loss: 0.0050, Time: 4.973797798156738\n",
      "Epoch 1625/9600, Train Loss: 0.0051, Time: 4.96934175491333\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import sys\n",
    "\n",
    "from modules.limu_model import limu_model4pretrain\n",
    "from modules.pretrain_hyperparameters import LIMU_Pretrain_Hyperparameters\n",
    "from utils.load_data_from_file import load_mixed_data, prepare_mixed_data_loader, load_one_out_data, \\\n",
    "    prepare_one_out_data_loader, limu_prepare_mixed_data_loader, limu_prepare_one_out_data_loader\n",
    "from utils.pretrain import pretrain_limu_model\n",
    "\n",
    "\n",
    "def main():\n",
    "    # Load the config from JSON file first\n",
    "    with open(\"utils/config.json\", \"r\") as file:\n",
    "        config = json.load(file)\n",
    "    print(config)\n",
    "\n",
    "    if config[\"general\"][\"test_mode\"] == \"Mixed\":\n",
    "        data, labels, encoder = load_mixed_data(window_size=config[\"general\"][\"window_size\"],\n",
    "                                                overlap=config[\"general\"][\"overlap\"])\n",
    "\n",
    "        num_classes = len(encoder.classes_)\n",
    "        feat_dim = data[0].shape[1]\n",
    "        labels_dim = labels.shape\n",
    "        print(f\"The shape of data is {data.shape}, the feat_dim is {feat_dim}, the labels_dim is {labels_dim}\")\n",
    "\n",
    "        eyegaze_data_loader = (limu_prepare_mixed_data_loader\n",
    "                               (config, data, labels, batch_size=config[\"general\"][\"batch_size\"],\n",
    "                                max_len=config[\"general\"][\"window_size\"]))\n",
    "\n",
    "    elif config[\"general\"][\"test_mode\"] == \"One_out\":\n",
    "        train_data, train_labels, test_data, test_labels, encoder = (load_one_out_data\n",
    "                                                                     (window_size=config[\"general\"][\"window_size\"],\n",
    "                                                                      overlap=config[\"general\"][\"overlap\"]))\n",
    "\n",
    "        num_classes = len(encoder.classes_)\n",
    "        feat_dim = train_data[0].shape[1]\n",
    "        print(f\"The number of classes is {num_classes}, the feat_dim is {feat_dim}\")\n",
    "\n",
    "        eyegaze_data_loader = (limu_prepare_one_out_data_loader\n",
    "                               (config, train_data, train_labels, test_data, test_labels,\n",
    "                                batch_size=config[\"general\"][\"batch_size\"],\n",
    "                                max_len=config[\"general\"][\"window_size\"]))\n",
    "    else:\n",
    "        print(\"Either Mixed / One_out\")\n",
    "        sys.exit()\n",
    "\n",
    "    hyperparameters = LIMU_Pretrain_Hyperparameters(config)\n",
    "    model = limu_model4pretrain(config, feat_dim)\n",
    "    loss = hyperparameters.loss\n",
    "    optimizer = hyperparameters.optimizer(model.parameters(), hyperparameters.lr, weight_decay=hyperparameters.weight_decay)\n",
    "\n",
    "    pretrain_limu_model(model, loss, optimizer, eyegaze_data_loader[0], config)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
